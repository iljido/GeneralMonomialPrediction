%Block size: 33
%Round = 1
%Test weight 
x0_0: BITVECTOR(33);
x0_1: BITVECTOR(33);

x1_0: BITVECTOR(33);
x1_1: BITVECTOR(33);

x2_0: BITVECTOR(33);
x2_1: BITVECTOR(33);

x3_0: BITVECTOR(33);
x3_1: BITVECTOR(33);

x4_0: BITVECTOR(33);
x4_1: BITVECTOR(33);

x5_0: BITVECTOR(33);
x5_1: BITVECTOR(33);

x6_0: BITVECTOR(33);
x6_1: BITVECTOR(33);

x7_0: BITVECTOR(33);
x7_1: BITVECTOR(33);

k0: BITVECTOR(33);

y0: BITVECTOR(33);

z0: BITVECTOR(33);

t0_0: BITVECTOR(33);

t1_0: BITVECTOR(33);

t2_0: BITVECTOR(33);

t3_0: BITVECTOR(33);

t4_0: BITVECTOR(33);

t5_0: BITVECTOR(33);

t6_0: BITVECTOR(33);

t7_0: BITVECTOR(33);


wk0 : BITVECTOR(7);
ASSERT wk0 = BVPLUS(7,0bin000000@(k0[0:0]),0bin000000@(k0[1:1]),0bin000000@(k0[2:2]),0bin000000@(k0[3:3]),0bin000000@(k0[4:4]),0bin000000@(k0[5:5]),0bin000000@(k0[6:6]),0bin000000@(k0[7:7]),0bin000000@(k0[8:8]),0bin000000@(k0[9:9]),0bin000000@(k0[10:10]),0bin000000@(k0[11:11]),0bin000000@(k0[12:12]),0bin000000@(k0[13:13]),0bin000000@(k0[14:14]),0bin000000@(k0[15:15]),0bin000000@(k0[16:16]),0bin000000@(k0[17:17]),0bin000000@(k0[18:18]),0bin000000@(k0[19:19]),0bin000000@(k0[20:20]),0bin000000@(k0[21:21]),0bin000000@(k0[22:22]),0bin000000@(k0[23:23]),0bin000000@(k0[24:24]),0bin000000@(k0[25:25]),0bin000000@(k0[26:26]),0bin000000@(k0[27:27]),0bin000000@(k0[28:28]),0bin000000@(k0[29:29]),0bin000000@(k0[30:30]),0bin000000@(k0[31:31]),0bin000000@(k0[32:32]));


wk : BITVECTOR(7);
ASSERT wk = wk0;
wx0 : BITVECTOR(9);
ASSERT wx0 = BVPLUS(9,0bin00000000@(x0_0[0:0]),0bin00000000@(x0_0[1:1]),0bin00000000@(x0_0[2:2]),0bin00000000@(x0_0[3:3]),0bin00000000@(x0_0[4:4]),0bin00000000@(x0_0[5:5]),0bin00000000@(x0_0[6:6]),0bin00000000@(x0_0[7:7]),0bin00000000@(x0_0[8:8]),0bin00000000@(x0_0[9:9]),0bin00000000@(x0_0[10:10]),0bin00000000@(x0_0[11:11]),0bin00000000@(x0_0[12:12]),0bin00000000@(x0_0[13:13]),0bin00000000@(x0_0[14:14]),0bin00000000@(x0_0[15:15]),0bin00000000@(x0_0[16:16]),0bin00000000@(x0_0[17:17]),0bin00000000@(x0_0[18:18]),0bin00000000@(x0_0[19:19]),0bin00000000@(x0_0[20:20]),0bin00000000@(x0_0[21:21]),0bin00000000@(x0_0[22:22]),0bin00000000@(x0_0[23:23]),0bin00000000@(x0_0[24:24]),0bin00000000@(x0_0[25:25]),0bin00000000@(x0_0[26:26]),0bin00000000@(x0_0[27:27]),0bin00000000@(x0_0[28:28]),0bin00000000@(x0_0[29:29]),0bin00000000@(x0_0[30:30]),0bin00000000@(x0_0[31:31]),0bin00000000@(x0_0[32:32]));


wx1: BITVECTOR(9);
ASSERT wx1 = BVPLUS(9,0bin00000000@(x1_0[0:0]),0bin00000000@(x1_0[1:1]),0bin00000000@(x1_0[2:2]),0bin00000000@(x1_0[3:3]),0bin00000000@(x1_0[4:4]),0bin00000000@(x1_0[5:5]),0bin00000000@(x1_0[6:6]),0bin00000000@(x1_0[7:7]),0bin00000000@(x1_0[8:8]),0bin00000000@(x1_0[9:9]),0bin00000000@(x1_0[10:10]),0bin00000000@(x1_0[11:11]),0bin00000000@(x1_0[12:12]),0bin00000000@(x1_0[13:13]),0bin00000000@(x1_0[14:14]),0bin00000000@(x1_0[15:15]),0bin00000000@(x1_0[16:16]),0bin00000000@(x1_0[17:17]),0bin00000000@(x1_0[18:18]),0bin00000000@(x1_0[19:19]),0bin00000000@(x1_0[20:20]),0bin00000000@(x1_0[21:21]),0bin00000000@(x1_0[22:22]),0bin00000000@(x1_0[23:23]),0bin00000000@(x1_0[24:24]),0bin00000000@(x1_0[25:25]),0bin00000000@(x1_0[26:26]),0bin00000000@(x1_0[27:27]),0bin00000000@(x1_0[28:28]),0bin00000000@(x1_0[29:29]),0bin00000000@(x1_0[30:30]),0bin00000000@(x1_0[31:31]),0bin00000000@(x1_0[32:32]));


wx2: BITVECTOR(9);
ASSERT wx2 = BVPLUS(9,0bin00000000@(x2_0[0:0]),0bin00000000@(x2_0[1:1]),0bin00000000@(x2_0[2:2]),0bin00000000@(x2_0[3:3]),0bin00000000@(x2_0[4:4]),0bin00000000@(x2_0[5:5]),0bin00000000@(x2_0[6:6]),0bin00000000@(x2_0[7:7]),0bin00000000@(x2_0[8:8]),0bin00000000@(x2_0[9:9]),0bin00000000@(x2_0[10:10]),0bin00000000@(x2_0[11:11]),0bin00000000@(x2_0[12:12]),0bin00000000@(x2_0[13:13]),0bin00000000@(x2_0[14:14]),0bin00000000@(x2_0[15:15]),0bin00000000@(x2_0[16:16]),0bin00000000@(x2_0[17:17]),0bin00000000@(x2_0[18:18]),0bin00000000@(x2_0[19:19]),0bin00000000@(x2_0[20:20]),0bin00000000@(x2_0[21:21]),0bin00000000@(x2_0[22:22]),0bin00000000@(x2_0[23:23]),0bin00000000@(x2_0[24:24]),0bin00000000@(x2_0[25:25]),0bin00000000@(x2_0[26:26]),0bin00000000@(x2_0[27:27]),0bin00000000@(x2_0[28:28]),0bin00000000@(x2_0[29:29]),0bin00000000@(x2_0[30:30]),0bin00000000@(x2_0[31:31]),0bin00000000@(x2_0[32:32]));


wx3: BITVECTOR(9);
ASSERT wx3 = BVPLUS(9,0bin00000000@(x3_0[0:0]),0bin00000000@(x3_0[1:1]),0bin00000000@(x3_0[2:2]),0bin00000000@(x3_0[3:3]),0bin00000000@(x3_0[4:4]),0bin00000000@(x3_0[5:5]),0bin00000000@(x3_0[6:6]),0bin00000000@(x3_0[7:7]),0bin00000000@(x3_0[8:8]),0bin00000000@(x3_0[9:9]),0bin00000000@(x3_0[10:10]),0bin00000000@(x3_0[11:11]),0bin00000000@(x3_0[12:12]),0bin00000000@(x3_0[13:13]),0bin00000000@(x3_0[14:14]),0bin00000000@(x3_0[15:15]),0bin00000000@(x3_0[16:16]),0bin00000000@(x3_0[17:17]),0bin00000000@(x3_0[18:18]),0bin00000000@(x3_0[19:19]),0bin00000000@(x3_0[20:20]),0bin00000000@(x3_0[21:21]),0bin00000000@(x3_0[22:22]),0bin00000000@(x3_0[23:23]),0bin00000000@(x3_0[24:24]),0bin00000000@(x3_0[25:25]),0bin00000000@(x3_0[26:26]),0bin00000000@(x3_0[27:27]),0bin00000000@(x3_0[28:28]),0bin00000000@(x3_0[29:29]),0bin00000000@(x3_0[30:30]),0bin00000000@(x3_0[31:31]),0bin00000000@(x3_0[32:32]));


wx4 : BITVECTOR(9);
ASSERT wx4 = BVPLUS(9,0bin00000000@(x4_0[0:0]),0bin00000000@(x4_0[1:1]),0bin00000000@(x4_0[2:2]),0bin00000000@(x4_0[3:3]),0bin00000000@(x4_0[4:4]),0bin00000000@(x4_0[5:5]),0bin00000000@(x4_0[6:6]),0bin00000000@(x4_0[7:7]),0bin00000000@(x4_0[8:8]),0bin00000000@(x4_0[9:9]),0bin00000000@(x4_0[10:10]),0bin00000000@(x4_0[11:11]),0bin00000000@(x4_0[12:12]),0bin00000000@(x4_0[13:13]),0bin00000000@(x4_0[14:14]),0bin00000000@(x4_0[15:15]),0bin00000000@(x4_0[16:16]),0bin00000000@(x4_0[17:17]),0bin00000000@(x4_0[18:18]),0bin00000000@(x4_0[19:19]),0bin00000000@(x4_0[20:20]),0bin00000000@(x4_0[21:21]),0bin00000000@(x4_0[22:22]),0bin00000000@(x4_0[23:23]),0bin00000000@(x4_0[24:24]),0bin00000000@(x4_0[25:25]),0bin00000000@(x4_0[26:26]),0bin00000000@(x4_0[27:27]),0bin00000000@(x4_0[28:28]),0bin00000000@(x4_0[29:29]),0bin00000000@(x4_0[30:30]),0bin00000000@(x4_0[31:31]),0bin00000000@(x4_0[32:32]));


wx5: BITVECTOR(9);
ASSERT wx5 = BVPLUS(9,0bin00000000@(x5_0[0:0]),0bin00000000@(x5_0[1:1]),0bin00000000@(x5_0[2:2]),0bin00000000@(x5_0[3:3]),0bin00000000@(x5_0[4:4]),0bin00000000@(x5_0[5:5]),0bin00000000@(x5_0[6:6]),0bin00000000@(x5_0[7:7]),0bin00000000@(x5_0[8:8]),0bin00000000@(x5_0[9:9]),0bin00000000@(x5_0[10:10]),0bin00000000@(x5_0[11:11]),0bin00000000@(x5_0[12:12]),0bin00000000@(x5_0[13:13]),0bin00000000@(x5_0[14:14]),0bin00000000@(x5_0[15:15]),0bin00000000@(x5_0[16:16]),0bin00000000@(x5_0[17:17]),0bin00000000@(x5_0[18:18]),0bin00000000@(x5_0[19:19]),0bin00000000@(x5_0[20:20]),0bin00000000@(x5_0[21:21]),0bin00000000@(x5_0[22:22]),0bin00000000@(x5_0[23:23]),0bin00000000@(x5_0[24:24]),0bin00000000@(x5_0[25:25]),0bin00000000@(x5_0[26:26]),0bin00000000@(x5_0[27:27]),0bin00000000@(x5_0[28:28]),0bin00000000@(x5_0[29:29]),0bin00000000@(x5_0[30:30]),0bin00000000@(x5_0[31:31]),0bin00000000@(x5_0[32:32]));


wx6: BITVECTOR(9);
ASSERT wx6 = BVPLUS(9,0bin00000000@(x6_0[0:0]),0bin00000000@(x6_0[1:1]),0bin00000000@(x6_0[2:2]),0bin00000000@(x6_0[3:3]),0bin00000000@(x6_0[4:4]),0bin00000000@(x6_0[5:5]),0bin00000000@(x6_0[6:6]),0bin00000000@(x6_0[7:7]),0bin00000000@(x6_0[8:8]),0bin00000000@(x6_0[9:9]),0bin00000000@(x6_0[10:10]),0bin00000000@(x6_0[11:11]),0bin00000000@(x6_0[12:12]),0bin00000000@(x6_0[13:13]),0bin00000000@(x6_0[14:14]),0bin00000000@(x6_0[15:15]),0bin00000000@(x6_0[16:16]),0bin00000000@(x6_0[17:17]),0bin00000000@(x6_0[18:18]),0bin00000000@(x6_0[19:19]),0bin00000000@(x6_0[20:20]),0bin00000000@(x6_0[21:21]),0bin00000000@(x6_0[22:22]),0bin00000000@(x6_0[23:23]),0bin00000000@(x6_0[24:24]),0bin00000000@(x6_0[25:25]),0bin00000000@(x6_0[26:26]),0bin00000000@(x6_0[27:27]),0bin00000000@(x6_0[28:28]),0bin00000000@(x6_0[29:29]),0bin00000000@(x6_0[30:30]),0bin00000000@(x6_0[31:31]),0bin00000000@(x6_0[32:32]));


wx7: BITVECTOR(9);
ASSERT wx7 = BVPLUS(9,0bin00000000@(x7_0[0:0]),0bin00000000@(x7_0[1:1]),0bin00000000@(x7_0[2:2]),0bin00000000@(x7_0[3:3]),0bin00000000@(x7_0[4:4]),0bin00000000@(x7_0[5:5]),0bin00000000@(x7_0[6:6]),0bin00000000@(x7_0[7:7]),0bin00000000@(x7_0[8:8]),0bin00000000@(x7_0[9:9]),0bin00000000@(x7_0[10:10]),0bin00000000@(x7_0[11:11]),0bin00000000@(x7_0[12:12]),0bin00000000@(x7_0[13:13]),0bin00000000@(x7_0[14:14]),0bin00000000@(x7_0[15:15]),0bin00000000@(x7_0[16:16]),0bin00000000@(x7_0[17:17]),0bin00000000@(x7_0[18:18]),0bin00000000@(x7_0[19:19]),0bin00000000@(x7_0[20:20]),0bin00000000@(x7_0[21:21]),0bin00000000@(x7_0[22:22]),0bin00000000@(x7_0[23:23]),0bin00000000@(x7_0[24:24]),0bin00000000@(x7_0[25:25]),0bin00000000@(x7_0[26:26]),0bin00000000@(x7_0[27:27]),0bin00000000@(x7_0[28:28]),0bin00000000@(x7_0[29:29]),0bin00000000@(x7_0[30:30]),0bin00000000@(x7_0[31:31]),0bin00000000@(x7_0[32:32]));


wx : BITVECTOR(9);
ASSERT wx = BVPLUS(9, wx0, wx1, wx2, wx3, wx4, wx5, wx6, wx7);


wx567 : BITVECTOR(9);
ASSERT wx567 = BVPLUS(9, wx5 , wx6 , wx7 );


ASSERT BVLE( x0_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x1_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x2_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x3_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x4_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x5_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x6_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x7_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x0_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x1_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x2_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x3_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x4_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x5_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x6_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x7_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( k0, 0bin111111111111111111111111111111111);
ASSERT BVLE( y0, 0bin111111111111111111111111111111111);
ASSERT BVLE( z0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t0_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t1_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t2_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t3_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t4_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t5_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t6_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t7_0, 0bin111111111111111111111111111111111);

ASSERT BVGE( x0_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x1_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x2_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x3_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x4_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x5_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x6_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x7_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x0_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x1_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x2_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x3_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x4_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x5_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x6_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x7_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( k0, 0bin000000000000000000000000000000000);
ASSERT BVGE( y0, 0bin000000000000000000000000000000000);
ASSERT BVGE( z0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t0_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t1_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t2_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t3_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t4_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t5_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t6_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t7_0, 0bin000000000000000000000000000000000);

ASSERT x0_1 = 0bin000000000000000000000000000000001;

ASSERT x1_1 = 0bin000000000000000000000000000000000;

ASSERT x2_1 = 0bin000000000000000000000000000000000;

ASSERT x3_1 = 0bin000000000000000000000000000000000;

ASSERT x4_1 = 0bin000000000000000000000000000000000;

ASSERT x5_1 = 0bin000000000000000000000000000000000;

ASSERT x6_1 = 0bin000000000000000000000000000000000;

ASSERT x7_1 = 0bin000000000000000000000000000000000;

t_x0_0 : BITVECTOR(1);
ASSERT t_x0_0@x0_0 = BVPLUS( 34 , 0bin0@x7_1, 0bin0@y0, 0bin000000000000000000000000000000000@t_x0_0);
ASSERT t_x0_0@x0_0 /= 0bin1000000000000000000000000000000000;

ASSERT z0 = BVPLUS(33,y0,k0);
ASSERT z0 & y0 = y0;


p_z0 : BITVECTOR(2);
ASSERT BVLE( p_z0 , 0bin10);
ASSERT BVGE( p_z0 , 0bin00);
ASSERT p_z0@z0 = BVPLUS( 35, BVMULT( 35, 0bin00000000000000000000000000000000011, 0bin00@t0_0 ),0bin000000000000000000000000000000000@p_z0);
t_t0_0 : BITVECTOR(3);
ASSERT BVLE( t_t0_0, 0bin111);
ASSERT BVGE( t_t0_0, 0bin000);
ASSERT t_t0_0@t0_0 = BVPLUS( 36 , 0bin000@t1_0, 0bin000@t2_0, 0bin000@t3_0, 0bin000@t4_0,0bin000@t5_0,0bin000@t6_0,0bin000@t7_0,0bin000000000000000000000000000000000@t_t0_0);
ASSERT (IF t0_0 = 0bin000000000000000000000000000000000 THEN t_t0_0 = 0bin000 ELSE BVGE( t_t0_0 , 0bin000) ENDIF);
ASSERT x0_1 = BVPLUS(33,t1_0,x1_0);
ASSERT x0_1 & t1_0 = t1_0;


ASSERT x1_1 = BVPLUS(33,t2_0,x2_0);
ASSERT x1_1 & t2_0 = t2_0;


ASSERT x2_1 = BVPLUS(33,t3_0,x3_0);
ASSERT x2_1 & t3_0 = t3_0;


ASSERT x3_1 = BVPLUS(33,t4_0,x4_0);
ASSERT x3_1 & t4_0 = t4_0;


ASSERT x4_1 = BVPLUS(33,t5_0,x5_0);
ASSERT x4_1 & t5_0 = t5_0;


ASSERT x5_1 = BVPLUS(33,t6_0,x6_0);
ASSERT x5_1 & t6_0 = t6_0;


ASSERT x6_1 = BVPLUS(33,t7_0,x7_0);
ASSERT x6_1 & t7_0 = t7_0;


ASSERT wk = 0bin10000000;
QUERY FALSE;
COUNTEREXAMPLE;
