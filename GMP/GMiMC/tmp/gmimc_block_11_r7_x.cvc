%Block size: 11
%Round = 7
%Test weight 
x0_0: BITVECTOR(11);
x0_1: BITVECTOR(11);
x0_2: BITVECTOR(11);
x0_3: BITVECTOR(11);
x0_4: BITVECTOR(11);
x0_5: BITVECTOR(11);
x0_6: BITVECTOR(11);
x0_7: BITVECTOR(11);

x1_0: BITVECTOR(11);
x1_1: BITVECTOR(11);
x1_2: BITVECTOR(11);
x1_3: BITVECTOR(11);
x1_4: BITVECTOR(11);
x1_5: BITVECTOR(11);
x1_6: BITVECTOR(11);
x1_7: BITVECTOR(11);

x2_0: BITVECTOR(11);
x2_1: BITVECTOR(11);
x2_2: BITVECTOR(11);
x2_3: BITVECTOR(11);
x2_4: BITVECTOR(11);
x2_5: BITVECTOR(11);
x2_6: BITVECTOR(11);
x2_7: BITVECTOR(11);

x3_0: BITVECTOR(11);
x3_1: BITVECTOR(11);
x3_2: BITVECTOR(11);
x3_3: BITVECTOR(11);
x3_4: BITVECTOR(11);
x3_5: BITVECTOR(11);
x3_6: BITVECTOR(11);
x3_7: BITVECTOR(11);

x4_0: BITVECTOR(11);
x4_1: BITVECTOR(11);
x4_2: BITVECTOR(11);
x4_3: BITVECTOR(11);
x4_4: BITVECTOR(11);
x4_5: BITVECTOR(11);
x4_6: BITVECTOR(11);
x4_7: BITVECTOR(11);

x5_0: BITVECTOR(11);
x5_1: BITVECTOR(11);
x5_2: BITVECTOR(11);
x5_3: BITVECTOR(11);
x5_4: BITVECTOR(11);
x5_5: BITVECTOR(11);
x5_6: BITVECTOR(11);
x5_7: BITVECTOR(11);

x6_0: BITVECTOR(11);
x6_1: BITVECTOR(11);
x6_2: BITVECTOR(11);
x6_3: BITVECTOR(11);
x6_4: BITVECTOR(11);
x6_5: BITVECTOR(11);
x6_6: BITVECTOR(11);
x6_7: BITVECTOR(11);

x7_0: BITVECTOR(11);
x7_1: BITVECTOR(11);
x7_2: BITVECTOR(11);
x7_3: BITVECTOR(11);
x7_4: BITVECTOR(11);
x7_5: BITVECTOR(11);
x7_6: BITVECTOR(11);
x7_7: BITVECTOR(11);

k0: BITVECTOR(11);
k1: BITVECTOR(11);
k2: BITVECTOR(11);
k3: BITVECTOR(11);
k4: BITVECTOR(11);
k5: BITVECTOR(11);
k6: BITVECTOR(11);

y0: BITVECTOR(11);
y1: BITVECTOR(11);
y2: BITVECTOR(11);
y3: BITVECTOR(11);
y4: BITVECTOR(11);
y5: BITVECTOR(11);
y6: BITVECTOR(11);

z0: BITVECTOR(11);
z1: BITVECTOR(11);
z2: BITVECTOR(11);
z3: BITVECTOR(11);
z4: BITVECTOR(11);
z5: BITVECTOR(11);
z6: BITVECTOR(11);

t0_0: BITVECTOR(11);
t0_1: BITVECTOR(11);
t0_2: BITVECTOR(11);
t0_3: BITVECTOR(11);
t0_4: BITVECTOR(11);
t0_5: BITVECTOR(11);
t0_6: BITVECTOR(11);

t1_0: BITVECTOR(11);
t1_1: BITVECTOR(11);
t1_2: BITVECTOR(11);
t1_3: BITVECTOR(11);
t1_4: BITVECTOR(11);
t1_5: BITVECTOR(11);
t1_6: BITVECTOR(11);

t2_0: BITVECTOR(11);
t2_1: BITVECTOR(11);
t2_2: BITVECTOR(11);
t2_3: BITVECTOR(11);
t2_4: BITVECTOR(11);
t2_5: BITVECTOR(11);
t2_6: BITVECTOR(11);

t3_0: BITVECTOR(11);
t3_1: BITVECTOR(11);
t3_2: BITVECTOR(11);
t3_3: BITVECTOR(11);
t3_4: BITVECTOR(11);
t3_5: BITVECTOR(11);
t3_6: BITVECTOR(11);

t4_0: BITVECTOR(11);
t4_1: BITVECTOR(11);
t4_2: BITVECTOR(11);
t4_3: BITVECTOR(11);
t4_4: BITVECTOR(11);
t4_5: BITVECTOR(11);
t4_6: BITVECTOR(11);

t5_0: BITVECTOR(11);
t5_1: BITVECTOR(11);
t5_2: BITVECTOR(11);
t5_3: BITVECTOR(11);
t5_4: BITVECTOR(11);
t5_5: BITVECTOR(11);
t5_6: BITVECTOR(11);

t6_0: BITVECTOR(11);
t6_1: BITVECTOR(11);
t6_2: BITVECTOR(11);
t6_3: BITVECTOR(11);
t6_4: BITVECTOR(11);
t6_5: BITVECTOR(11);
t6_6: BITVECTOR(11);

t7_0: BITVECTOR(11);
t7_1: BITVECTOR(11);
t7_2: BITVECTOR(11);
t7_3: BITVECTOR(11);
t7_4: BITVECTOR(11);
t7_5: BITVECTOR(11);
t7_6: BITVECTOR(11);


wk0 : BITVECTOR(8);
ASSERT wk0 = BVPLUS(8,0bin0000000@(k0[0:0]),0bin0000000@(k0[1:1]),0bin0000000@(k0[2:2]),0bin0000000@(k0[3:3]),0bin0000000@(k0[4:4]),0bin0000000@(k0[5:5]),0bin0000000@(k0[6:6]),0bin0000000@(k0[7:7]),0bin0000000@(k0[8:8]),0bin0000000@(k0[9:9]),0bin0000000@(k0[10:10]));


wk1 : BITVECTOR(8);
ASSERT wk1 = BVPLUS(8,0bin0000000@(k1[0:0]),0bin0000000@(k1[1:1]),0bin0000000@(k1[2:2]),0bin0000000@(k1[3:3]),0bin0000000@(k1[4:4]),0bin0000000@(k1[5:5]),0bin0000000@(k1[6:6]),0bin0000000@(k1[7:7]),0bin0000000@(k1[8:8]),0bin0000000@(k1[9:9]),0bin0000000@(k1[10:10]));


wk2 : BITVECTOR(8);
ASSERT wk2 = BVPLUS(8,0bin0000000@(k2[0:0]),0bin0000000@(k2[1:1]),0bin0000000@(k2[2:2]),0bin0000000@(k2[3:3]),0bin0000000@(k2[4:4]),0bin0000000@(k2[5:5]),0bin0000000@(k2[6:6]),0bin0000000@(k2[7:7]),0bin0000000@(k2[8:8]),0bin0000000@(k2[9:9]),0bin0000000@(k2[10:10]));


wk3 : BITVECTOR(8);
ASSERT wk3 = BVPLUS(8,0bin0000000@(k3[0:0]),0bin0000000@(k3[1:1]),0bin0000000@(k3[2:2]),0bin0000000@(k3[3:3]),0bin0000000@(k3[4:4]),0bin0000000@(k3[5:5]),0bin0000000@(k3[6:6]),0bin0000000@(k3[7:7]),0bin0000000@(k3[8:8]),0bin0000000@(k3[9:9]),0bin0000000@(k3[10:10]));


wk4 : BITVECTOR(8);
ASSERT wk4 = BVPLUS(8,0bin0000000@(k4[0:0]),0bin0000000@(k4[1:1]),0bin0000000@(k4[2:2]),0bin0000000@(k4[3:3]),0bin0000000@(k4[4:4]),0bin0000000@(k4[5:5]),0bin0000000@(k4[6:6]),0bin0000000@(k4[7:7]),0bin0000000@(k4[8:8]),0bin0000000@(k4[9:9]),0bin0000000@(k4[10:10]));


wk5 : BITVECTOR(8);
ASSERT wk5 = BVPLUS(8,0bin0000000@(k5[0:0]),0bin0000000@(k5[1:1]),0bin0000000@(k5[2:2]),0bin0000000@(k5[3:3]),0bin0000000@(k5[4:4]),0bin0000000@(k5[5:5]),0bin0000000@(k5[6:6]),0bin0000000@(k5[7:7]),0bin0000000@(k5[8:8]),0bin0000000@(k5[9:9]),0bin0000000@(k5[10:10]));


wk6 : BITVECTOR(8);
ASSERT wk6 = BVPLUS(8,0bin0000000@(k6[0:0]),0bin0000000@(k6[1:1]),0bin0000000@(k6[2:2]),0bin0000000@(k6[3:3]),0bin0000000@(k6[4:4]),0bin0000000@(k6[5:5]),0bin0000000@(k6[6:6]),0bin0000000@(k6[7:7]),0bin0000000@(k6[8:8]),0bin0000000@(k6[9:9]),0bin0000000@(k6[10:10]));


wk : BITVECTOR(8);
ASSERT wk = BVPLUS(8, wk0, wk1, wk2, wk3, wk4, wk5, wk6);


wx0 : BITVECTOR(7);
ASSERT wx0 = BVPLUS(7,0bin000000@(x0_0[0:0]),0bin000000@(x0_0[1:1]),0bin000000@(x0_0[2:2]),0bin000000@(x0_0[3:3]),0bin000000@(x0_0[4:4]),0bin000000@(x0_0[5:5]),0bin000000@(x0_0[6:6]),0bin000000@(x0_0[7:7]),0bin000000@(x0_0[8:8]),0bin000000@(x0_0[9:9]),0bin000000@(x0_0[10:10]));


wx1: BITVECTOR(7);
ASSERT wx1 = BVPLUS(7,0bin000000@(x1_0[0:0]),0bin000000@(x1_0[1:1]),0bin000000@(x1_0[2:2]),0bin000000@(x1_0[3:3]),0bin000000@(x1_0[4:4]),0bin000000@(x1_0[5:5]),0bin000000@(x1_0[6:6]),0bin000000@(x1_0[7:7]),0bin000000@(x1_0[8:8]),0bin000000@(x1_0[9:9]),0bin000000@(x1_0[10:10]));


wx2: BITVECTOR(7);
ASSERT wx2 = BVPLUS(7,0bin000000@(x2_0[0:0]),0bin000000@(x2_0[1:1]),0bin000000@(x2_0[2:2]),0bin000000@(x2_0[3:3]),0bin000000@(x2_0[4:4]),0bin000000@(x2_0[5:5]),0bin000000@(x2_0[6:6]),0bin000000@(x2_0[7:7]),0bin000000@(x2_0[8:8]),0bin000000@(x2_0[9:9]),0bin000000@(x2_0[10:10]));


wx3: BITVECTOR(7);
ASSERT wx3 = BVPLUS(7,0bin000000@(x3_0[0:0]),0bin000000@(x3_0[1:1]),0bin000000@(x3_0[2:2]),0bin000000@(x3_0[3:3]),0bin000000@(x3_0[4:4]),0bin000000@(x3_0[5:5]),0bin000000@(x3_0[6:6]),0bin000000@(x3_0[7:7]),0bin000000@(x3_0[8:8]),0bin000000@(x3_0[9:9]),0bin000000@(x3_0[10:10]));


wx4 : BITVECTOR(7);
ASSERT wx4 = BVPLUS(7,0bin000000@(x4_0[0:0]),0bin000000@(x4_0[1:1]),0bin000000@(x4_0[2:2]),0bin000000@(x4_0[3:3]),0bin000000@(x4_0[4:4]),0bin000000@(x4_0[5:5]),0bin000000@(x4_0[6:6]),0bin000000@(x4_0[7:7]),0bin000000@(x4_0[8:8]),0bin000000@(x4_0[9:9]),0bin000000@(x4_0[10:10]));


wx5: BITVECTOR(7);
ASSERT wx5 = BVPLUS(7,0bin000000@(x5_0[0:0]),0bin000000@(x5_0[1:1]),0bin000000@(x5_0[2:2]),0bin000000@(x5_0[3:3]),0bin000000@(x5_0[4:4]),0bin000000@(x5_0[5:5]),0bin000000@(x5_0[6:6]),0bin000000@(x5_0[7:7]),0bin000000@(x5_0[8:8]),0bin000000@(x5_0[9:9]),0bin000000@(x5_0[10:10]));


wx6: BITVECTOR(7);
ASSERT wx6 = BVPLUS(7,0bin000000@(x6_0[0:0]),0bin000000@(x6_0[1:1]),0bin000000@(x6_0[2:2]),0bin000000@(x6_0[3:3]),0bin000000@(x6_0[4:4]),0bin000000@(x6_0[5:5]),0bin000000@(x6_0[6:6]),0bin000000@(x6_0[7:7]),0bin000000@(x6_0[8:8]),0bin000000@(x6_0[9:9]),0bin000000@(x6_0[10:10]));


wx7: BITVECTOR(7);
ASSERT wx7 = BVPLUS(7,0bin000000@(x7_0[0:0]),0bin000000@(x7_0[1:1]),0bin000000@(x7_0[2:2]),0bin000000@(x7_0[3:3]),0bin000000@(x7_0[4:4]),0bin000000@(x7_0[5:5]),0bin000000@(x7_0[6:6]),0bin000000@(x7_0[7:7]),0bin000000@(x7_0[8:8]),0bin000000@(x7_0[9:9]),0bin000000@(x7_0[10:10]));


wx : BITVECTOR(7);
ASSERT wx = BVPLUS(7, wx0, wx1, wx2, wx3, wx4, wx5, wx6, wx7);


wx567 : BITVECTOR(7);
ASSERT wx567 = BVPLUS(7, wx5 , wx6 , wx7 );


ASSERT BVLE( x0_0, 0bin11111111111);
ASSERT BVLE( x1_0, 0bin11111111111);
ASSERT BVLE( x2_0, 0bin11111111111);
ASSERT BVLE( x3_0, 0bin11111111111);
ASSERT BVLE( x4_0, 0bin11111111111);
ASSERT BVLE( x5_0, 0bin11111111111);
ASSERT BVLE( x6_0, 0bin11111111111);
ASSERT BVLE( x7_0, 0bin11111111111);
ASSERT BVLE( x0_1, 0bin11111111111);
ASSERT BVLE( x1_1, 0bin11111111111);
ASSERT BVLE( x2_1, 0bin11111111111);
ASSERT BVLE( x3_1, 0bin11111111111);
ASSERT BVLE( x4_1, 0bin11111111111);
ASSERT BVLE( x5_1, 0bin11111111111);
ASSERT BVLE( x6_1, 0bin11111111111);
ASSERT BVLE( x7_1, 0bin11111111111);
ASSERT BVLE( x0_2, 0bin11111111111);
ASSERT BVLE( x1_2, 0bin11111111111);
ASSERT BVLE( x2_2, 0bin11111111111);
ASSERT BVLE( x3_2, 0bin11111111111);
ASSERT BVLE( x4_2, 0bin11111111111);
ASSERT BVLE( x5_2, 0bin11111111111);
ASSERT BVLE( x6_2, 0bin11111111111);
ASSERT BVLE( x7_2, 0bin11111111111);
ASSERT BVLE( x0_3, 0bin11111111111);
ASSERT BVLE( x1_3, 0bin11111111111);
ASSERT BVLE( x2_3, 0bin11111111111);
ASSERT BVLE( x3_3, 0bin11111111111);
ASSERT BVLE( x4_3, 0bin11111111111);
ASSERT BVLE( x5_3, 0bin11111111111);
ASSERT BVLE( x6_3, 0bin11111111111);
ASSERT BVLE( x7_3, 0bin11111111111);
ASSERT BVLE( x0_4, 0bin11111111111);
ASSERT BVLE( x1_4, 0bin11111111111);
ASSERT BVLE( x2_4, 0bin11111111111);
ASSERT BVLE( x3_4, 0bin11111111111);
ASSERT BVLE( x4_4, 0bin11111111111);
ASSERT BVLE( x5_4, 0bin11111111111);
ASSERT BVLE( x6_4, 0bin11111111111);
ASSERT BVLE( x7_4, 0bin11111111111);
ASSERT BVLE( x0_5, 0bin11111111111);
ASSERT BVLE( x1_5, 0bin11111111111);
ASSERT BVLE( x2_5, 0bin11111111111);
ASSERT BVLE( x3_5, 0bin11111111111);
ASSERT BVLE( x4_5, 0bin11111111111);
ASSERT BVLE( x5_5, 0bin11111111111);
ASSERT BVLE( x6_5, 0bin11111111111);
ASSERT BVLE( x7_5, 0bin11111111111);
ASSERT BVLE( x0_6, 0bin11111111111);
ASSERT BVLE( x1_6, 0bin11111111111);
ASSERT BVLE( x2_6, 0bin11111111111);
ASSERT BVLE( x3_6, 0bin11111111111);
ASSERT BVLE( x4_6, 0bin11111111111);
ASSERT BVLE( x5_6, 0bin11111111111);
ASSERT BVLE( x6_6, 0bin11111111111);
ASSERT BVLE( x7_6, 0bin11111111111);
ASSERT BVLE( x0_7, 0bin11111111111);
ASSERT BVLE( x1_7, 0bin11111111111);
ASSERT BVLE( x2_7, 0bin11111111111);
ASSERT BVLE( x3_7, 0bin11111111111);
ASSERT BVLE( x4_7, 0bin11111111111);
ASSERT BVLE( x5_7, 0bin11111111111);
ASSERT BVLE( x6_7, 0bin11111111111);
ASSERT BVLE( x7_7, 0bin11111111111);
ASSERT BVLE( k0, 0bin11111111111);
ASSERT BVLE( y0, 0bin11111111111);
ASSERT BVLE( z0, 0bin11111111111);
ASSERT BVLE( k1, 0bin11111111111);
ASSERT BVLE( y1, 0bin11111111111);
ASSERT BVLE( z1, 0bin11111111111);
ASSERT BVLE( k2, 0bin11111111111);
ASSERT BVLE( y2, 0bin11111111111);
ASSERT BVLE( z2, 0bin11111111111);
ASSERT BVLE( k3, 0bin11111111111);
ASSERT BVLE( y3, 0bin11111111111);
ASSERT BVLE( z3, 0bin11111111111);
ASSERT BVLE( k4, 0bin11111111111);
ASSERT BVLE( y4, 0bin11111111111);
ASSERT BVLE( z4, 0bin11111111111);
ASSERT BVLE( k5, 0bin11111111111);
ASSERT BVLE( y5, 0bin11111111111);
ASSERT BVLE( z5, 0bin11111111111);
ASSERT BVLE( k6, 0bin11111111111);
ASSERT BVLE( y6, 0bin11111111111);
ASSERT BVLE( z6, 0bin11111111111);
ASSERT BVLE( t0_0, 0bin11111111111);
ASSERT BVLE( t1_0, 0bin11111111111);
ASSERT BVLE( t2_0, 0bin11111111111);
ASSERT BVLE( t3_0, 0bin11111111111);
ASSERT BVLE( t4_0, 0bin11111111111);
ASSERT BVLE( t5_0, 0bin11111111111);
ASSERT BVLE( t6_0, 0bin11111111111);
ASSERT BVLE( t7_0, 0bin11111111111);
ASSERT BVLE( t0_1, 0bin11111111111);
ASSERT BVLE( t1_1, 0bin11111111111);
ASSERT BVLE( t2_1, 0bin11111111111);
ASSERT BVLE( t3_1, 0bin11111111111);
ASSERT BVLE( t4_1, 0bin11111111111);
ASSERT BVLE( t5_1, 0bin11111111111);
ASSERT BVLE( t6_1, 0bin11111111111);
ASSERT BVLE( t7_1, 0bin11111111111);
ASSERT BVLE( t0_2, 0bin11111111111);
ASSERT BVLE( t1_2, 0bin11111111111);
ASSERT BVLE( t2_2, 0bin11111111111);
ASSERT BVLE( t3_2, 0bin11111111111);
ASSERT BVLE( t4_2, 0bin11111111111);
ASSERT BVLE( t5_2, 0bin11111111111);
ASSERT BVLE( t6_2, 0bin11111111111);
ASSERT BVLE( t7_2, 0bin11111111111);
ASSERT BVLE( t0_3, 0bin11111111111);
ASSERT BVLE( t1_3, 0bin11111111111);
ASSERT BVLE( t2_3, 0bin11111111111);
ASSERT BVLE( t3_3, 0bin11111111111);
ASSERT BVLE( t4_3, 0bin11111111111);
ASSERT BVLE( t5_3, 0bin11111111111);
ASSERT BVLE( t6_3, 0bin11111111111);
ASSERT BVLE( t7_3, 0bin11111111111);
ASSERT BVLE( t0_4, 0bin11111111111);
ASSERT BVLE( t1_4, 0bin11111111111);
ASSERT BVLE( t2_4, 0bin11111111111);
ASSERT BVLE( t3_4, 0bin11111111111);
ASSERT BVLE( t4_4, 0bin11111111111);
ASSERT BVLE( t5_4, 0bin11111111111);
ASSERT BVLE( t6_4, 0bin11111111111);
ASSERT BVLE( t7_4, 0bin11111111111);
ASSERT BVLE( t0_5, 0bin11111111111);
ASSERT BVLE( t1_5, 0bin11111111111);
ASSERT BVLE( t2_5, 0bin11111111111);
ASSERT BVLE( t3_5, 0bin11111111111);
ASSERT BVLE( t4_5, 0bin11111111111);
ASSERT BVLE( t5_5, 0bin11111111111);
ASSERT BVLE( t6_5, 0bin11111111111);
ASSERT BVLE( t7_5, 0bin11111111111);
ASSERT BVLE( t0_6, 0bin11111111111);
ASSERT BVLE( t1_6, 0bin11111111111);
ASSERT BVLE( t2_6, 0bin11111111111);
ASSERT BVLE( t3_6, 0bin11111111111);
ASSERT BVLE( t4_6, 0bin11111111111);
ASSERT BVLE( t5_6, 0bin11111111111);
ASSERT BVLE( t6_6, 0bin11111111111);
ASSERT BVLE( t7_6, 0bin11111111111);

ASSERT BVGE( x0_0, 0bin00000000000);
ASSERT BVGE( x1_0, 0bin00000000000);
ASSERT BVGE( x2_0, 0bin00000000000);
ASSERT BVGE( x3_0, 0bin00000000000);
ASSERT BVGE( x4_0, 0bin00000000000);
ASSERT BVGE( x5_0, 0bin00000000000);
ASSERT BVGE( x6_0, 0bin00000000000);
ASSERT BVGE( x7_0, 0bin00000000000);
ASSERT BVGE( x0_1, 0bin00000000000);
ASSERT BVGE( x1_1, 0bin00000000000);
ASSERT BVGE( x2_1, 0bin00000000000);
ASSERT BVGE( x3_1, 0bin00000000000);
ASSERT BVGE( x4_1, 0bin00000000000);
ASSERT BVGE( x5_1, 0bin00000000000);
ASSERT BVGE( x6_1, 0bin00000000000);
ASSERT BVGE( x7_1, 0bin00000000000);
ASSERT BVGE( x0_2, 0bin00000000000);
ASSERT BVGE( x1_2, 0bin00000000000);
ASSERT BVGE( x2_2, 0bin00000000000);
ASSERT BVGE( x3_2, 0bin00000000000);
ASSERT BVGE( x4_2, 0bin00000000000);
ASSERT BVGE( x5_2, 0bin00000000000);
ASSERT BVGE( x6_2, 0bin00000000000);
ASSERT BVGE( x7_2, 0bin00000000000);
ASSERT BVGE( x0_3, 0bin00000000000);
ASSERT BVGE( x1_3, 0bin00000000000);
ASSERT BVGE( x2_3, 0bin00000000000);
ASSERT BVGE( x3_3, 0bin00000000000);
ASSERT BVGE( x4_3, 0bin00000000000);
ASSERT BVGE( x5_3, 0bin00000000000);
ASSERT BVGE( x6_3, 0bin00000000000);
ASSERT BVGE( x7_3, 0bin00000000000);
ASSERT BVGE( x0_4, 0bin00000000000);
ASSERT BVGE( x1_4, 0bin00000000000);
ASSERT BVGE( x2_4, 0bin00000000000);
ASSERT BVGE( x3_4, 0bin00000000000);
ASSERT BVGE( x4_4, 0bin00000000000);
ASSERT BVGE( x5_4, 0bin00000000000);
ASSERT BVGE( x6_4, 0bin00000000000);
ASSERT BVGE( x7_4, 0bin00000000000);
ASSERT BVGE( x0_5, 0bin00000000000);
ASSERT BVGE( x1_5, 0bin00000000000);
ASSERT BVGE( x2_5, 0bin00000000000);
ASSERT BVGE( x3_5, 0bin00000000000);
ASSERT BVGE( x4_5, 0bin00000000000);
ASSERT BVGE( x5_5, 0bin00000000000);
ASSERT BVGE( x6_5, 0bin00000000000);
ASSERT BVGE( x7_5, 0bin00000000000);
ASSERT BVGE( x0_6, 0bin00000000000);
ASSERT BVGE( x1_6, 0bin00000000000);
ASSERT BVGE( x2_6, 0bin00000000000);
ASSERT BVGE( x3_6, 0bin00000000000);
ASSERT BVGE( x4_6, 0bin00000000000);
ASSERT BVGE( x5_6, 0bin00000000000);
ASSERT BVGE( x6_6, 0bin00000000000);
ASSERT BVGE( x7_6, 0bin00000000000);
ASSERT BVGE( x0_7, 0bin00000000000);
ASSERT BVGE( x1_7, 0bin00000000000);
ASSERT BVGE( x2_7, 0bin00000000000);
ASSERT BVGE( x3_7, 0bin00000000000);
ASSERT BVGE( x4_7, 0bin00000000000);
ASSERT BVGE( x5_7, 0bin00000000000);
ASSERT BVGE( x6_7, 0bin00000000000);
ASSERT BVGE( x7_7, 0bin00000000000);
ASSERT BVGE( k0, 0bin00000000000);
ASSERT BVGE( y0, 0bin00000000000);
ASSERT BVGE( z0, 0bin00000000000);
ASSERT BVGE( k1, 0bin00000000000);
ASSERT BVGE( y1, 0bin00000000000);
ASSERT BVGE( z1, 0bin00000000000);
ASSERT BVGE( k2, 0bin00000000000);
ASSERT BVGE( y2, 0bin00000000000);
ASSERT BVGE( z2, 0bin00000000000);
ASSERT BVGE( k3, 0bin00000000000);
ASSERT BVGE( y3, 0bin00000000000);
ASSERT BVGE( z3, 0bin00000000000);
ASSERT BVGE( k4, 0bin00000000000);
ASSERT BVGE( y4, 0bin00000000000);
ASSERT BVGE( z4, 0bin00000000000);
ASSERT BVGE( k5, 0bin00000000000);
ASSERT BVGE( y5, 0bin00000000000);
ASSERT BVGE( z5, 0bin00000000000);
ASSERT BVGE( k6, 0bin00000000000);
ASSERT BVGE( y6, 0bin00000000000);
ASSERT BVGE( z6, 0bin00000000000);
ASSERT BVGE( t0_0, 0bin00000000000);
ASSERT BVGE( t1_0, 0bin00000000000);
ASSERT BVGE( t2_0, 0bin00000000000);
ASSERT BVGE( t3_0, 0bin00000000000);
ASSERT BVGE( t4_0, 0bin00000000000);
ASSERT BVGE( t5_0, 0bin00000000000);
ASSERT BVGE( t6_0, 0bin00000000000);
ASSERT BVGE( t7_0, 0bin00000000000);
ASSERT BVGE( t0_1, 0bin00000000000);
ASSERT BVGE( t1_1, 0bin00000000000);
ASSERT BVGE( t2_1, 0bin00000000000);
ASSERT BVGE( t3_1, 0bin00000000000);
ASSERT BVGE( t4_1, 0bin00000000000);
ASSERT BVGE( t5_1, 0bin00000000000);
ASSERT BVGE( t6_1, 0bin00000000000);
ASSERT BVGE( t7_1, 0bin00000000000);
ASSERT BVGE( t0_2, 0bin00000000000);
ASSERT BVGE( t1_2, 0bin00000000000);
ASSERT BVGE( t2_2, 0bin00000000000);
ASSERT BVGE( t3_2, 0bin00000000000);
ASSERT BVGE( t4_2, 0bin00000000000);
ASSERT BVGE( t5_2, 0bin00000000000);
ASSERT BVGE( t6_2, 0bin00000000000);
ASSERT BVGE( t7_2, 0bin00000000000);
ASSERT BVGE( t0_3, 0bin00000000000);
ASSERT BVGE( t1_3, 0bin00000000000);
ASSERT BVGE( t2_3, 0bin00000000000);
ASSERT BVGE( t3_3, 0bin00000000000);
ASSERT BVGE( t4_3, 0bin00000000000);
ASSERT BVGE( t5_3, 0bin00000000000);
ASSERT BVGE( t6_3, 0bin00000000000);
ASSERT BVGE( t7_3, 0bin00000000000);
ASSERT BVGE( t0_4, 0bin00000000000);
ASSERT BVGE( t1_4, 0bin00000000000);
ASSERT BVGE( t2_4, 0bin00000000000);
ASSERT BVGE( t3_4, 0bin00000000000);
ASSERT BVGE( t4_4, 0bin00000000000);
ASSERT BVGE( t5_4, 0bin00000000000);
ASSERT BVGE( t6_4, 0bin00000000000);
ASSERT BVGE( t7_4, 0bin00000000000);
ASSERT BVGE( t0_5, 0bin00000000000);
ASSERT BVGE( t1_5, 0bin00000000000);
ASSERT BVGE( t2_5, 0bin00000000000);
ASSERT BVGE( t3_5, 0bin00000000000);
ASSERT BVGE( t4_5, 0bin00000000000);
ASSERT BVGE( t5_5, 0bin00000000000);
ASSERT BVGE( t6_5, 0bin00000000000);
ASSERT BVGE( t7_5, 0bin00000000000);
ASSERT BVGE( t0_6, 0bin00000000000);
ASSERT BVGE( t1_6, 0bin00000000000);
ASSERT BVGE( t2_6, 0bin00000000000);
ASSERT BVGE( t3_6, 0bin00000000000);
ASSERT BVGE( t4_6, 0bin00000000000);
ASSERT BVGE( t5_6, 0bin00000000000);
ASSERT BVGE( t6_6, 0bin00000000000);
ASSERT BVGE( t7_6, 0bin00000000000);

ASSERT x0_7 = 0bin00000000001;

ASSERT x1_7 = 0bin00000000000;

ASSERT x2_7 = 0bin00000000000;

ASSERT x3_7 = 0bin00000000000;

ASSERT x4_7 = 0bin00000000000;

ASSERT x5_7 = 0bin00000000000;

ASSERT x6_7 = 0bin00000000000;

ASSERT x7_7 = 0bin00000000000;

t_x0_0 : BITVECTOR(1);
ASSERT t_x0_0@x0_0 = BVPLUS( 12 , 0bin0@x7_1, 0bin0@y0, 0bin00000000000@t_x0_0);
ASSERT t_x0_0@x0_0 /= 0bin100000000000;

ASSERT z0 = BVPLUS(11,y0,k0);
ASSERT z0 & y0 = y0;


p_z0 : BITVECTOR(2);
ASSERT BVLE( p_z0 , 0bin10);
ASSERT BVGE( p_z0 , 0bin00);
ASSERT p_z0@z0 = BVPLUS( 13, BVMULT( 13, 0bin0000000000011, 0bin00@t0_0 ),0bin00000000000@p_z0);
t_t0_0 : BITVECTOR(3);
ASSERT BVLE( t_t0_0, 0bin111);
ASSERT BVGE( t_t0_0, 0bin000);
ASSERT t_t0_0@t0_0 = BVPLUS( 14 , 0bin000@t1_0, 0bin000@t2_0, 0bin000@t3_0, 0bin000@t4_0,0bin000@t5_0,0bin000@t6_0,0bin000@t7_0,0bin00000000000@t_t0_0);
ASSERT (IF t0_0 = 0bin00000000000 THEN t_t0_0 = 0bin000 ELSE BVGE( t_t0_0 , 0bin000) ENDIF);
ASSERT x0_1 = BVPLUS(11,t1_0,x1_0);
ASSERT x0_1 & t1_0 = t1_0;


ASSERT x1_1 = BVPLUS(11,t2_0,x2_0);
ASSERT x1_1 & t2_0 = t2_0;


ASSERT x2_1 = BVPLUS(11,t3_0,x3_0);
ASSERT x2_1 & t3_0 = t3_0;


ASSERT x3_1 = BVPLUS(11,t4_0,x4_0);
ASSERT x3_1 & t4_0 = t4_0;


ASSERT x4_1 = BVPLUS(11,t5_0,x5_0);
ASSERT x4_1 & t5_0 = t5_0;


ASSERT x5_1 = BVPLUS(11,t6_0,x6_0);
ASSERT x5_1 & t6_0 = t6_0;


ASSERT x6_1 = BVPLUS(11,t7_0,x7_0);
ASSERT x6_1 & t7_0 = t7_0;


t_x0_1 : BITVECTOR(1);
ASSERT t_x0_1@x0_1 = BVPLUS( 12 , 0bin0@x7_2, 0bin0@y1, 0bin00000000000@t_x0_1);
ASSERT t_x0_1@x0_1 /= 0bin100000000000;

ASSERT z1 = BVPLUS(11,y1,k1);
ASSERT z1 & y1 = y1;


p_z1 : BITVECTOR(2);
ASSERT BVLE( p_z1 , 0bin10);
ASSERT BVGE( p_z1 , 0bin00);
ASSERT p_z1@z1 = BVPLUS( 13, BVMULT( 13, 0bin0000000000011, 0bin00@t0_1 ),0bin00000000000@p_z1);
t_t0_1 : BITVECTOR(3);
ASSERT BVLE( t_t0_1, 0bin111);
ASSERT BVGE( t_t0_1, 0bin000);
ASSERT t_t0_1@t0_1 = BVPLUS( 14 , 0bin000@t1_1, 0bin000@t2_1, 0bin000@t3_1, 0bin000@t4_1,0bin000@t5_1,0bin000@t6_1,0bin000@t7_1,0bin00000000000@t_t0_1);
ASSERT (IF t0_1 = 0bin00000000000 THEN t_t0_1 = 0bin000 ELSE BVGE( t_t0_1 , 0bin000) ENDIF);
ASSERT x0_2 = BVPLUS(11,t1_1,x1_1);
ASSERT x0_2 & t1_1 = t1_1;


ASSERT x1_2 = BVPLUS(11,t2_1,x2_1);
ASSERT x1_2 & t2_1 = t2_1;


ASSERT x2_2 = BVPLUS(11,t3_1,x3_1);
ASSERT x2_2 & t3_1 = t3_1;


ASSERT x3_2 = BVPLUS(11,t4_1,x4_1);
ASSERT x3_2 & t4_1 = t4_1;


ASSERT x4_2 = BVPLUS(11,t5_1,x5_1);
ASSERT x4_2 & t5_1 = t5_1;


ASSERT x5_2 = BVPLUS(11,t6_1,x6_1);
ASSERT x5_2 & t6_1 = t6_1;


ASSERT x6_2 = BVPLUS(11,t7_1,x7_1);
ASSERT x6_2 & t7_1 = t7_1;


t_x0_2 : BITVECTOR(1);
ASSERT t_x0_2@x0_2 = BVPLUS( 12 , 0bin0@x7_3, 0bin0@y2, 0bin00000000000@t_x0_2);
ASSERT t_x0_2@x0_2 /= 0bin100000000000;

ASSERT z2 = BVPLUS(11,y2,k2);
ASSERT z2 & y2 = y2;


p_z2 : BITVECTOR(2);
ASSERT BVLE( p_z2 , 0bin10);
ASSERT BVGE( p_z2 , 0bin00);
ASSERT p_z2@z2 = BVPLUS( 13, BVMULT( 13, 0bin0000000000011, 0bin00@t0_2 ),0bin00000000000@p_z2);
t_t0_2 : BITVECTOR(3);
ASSERT BVLE( t_t0_2, 0bin111);
ASSERT BVGE( t_t0_2, 0bin000);
ASSERT t_t0_2@t0_2 = BVPLUS( 14 , 0bin000@t1_2, 0bin000@t2_2, 0bin000@t3_2, 0bin000@t4_2,0bin000@t5_2,0bin000@t6_2,0bin000@t7_2,0bin00000000000@t_t0_2);
ASSERT (IF t0_2 = 0bin00000000000 THEN t_t0_2 = 0bin000 ELSE BVGE( t_t0_2 , 0bin000) ENDIF);
ASSERT x0_3 = BVPLUS(11,t1_2,x1_2);
ASSERT x0_3 & t1_2 = t1_2;


ASSERT x1_3 = BVPLUS(11,t2_2,x2_2);
ASSERT x1_3 & t2_2 = t2_2;


ASSERT x2_3 = BVPLUS(11,t3_2,x3_2);
ASSERT x2_3 & t3_2 = t3_2;


ASSERT x3_3 = BVPLUS(11,t4_2,x4_2);
ASSERT x3_3 & t4_2 = t4_2;


ASSERT x4_3 = BVPLUS(11,t5_2,x5_2);
ASSERT x4_3 & t5_2 = t5_2;


ASSERT x5_3 = BVPLUS(11,t6_2,x6_2);
ASSERT x5_3 & t6_2 = t6_2;


ASSERT x6_3 = BVPLUS(11,t7_2,x7_2);
ASSERT x6_3 & t7_2 = t7_2;


t_x0_3 : BITVECTOR(1);
ASSERT t_x0_3@x0_3 = BVPLUS( 12 , 0bin0@x7_4, 0bin0@y3, 0bin00000000000@t_x0_3);
ASSERT t_x0_3@x0_3 /= 0bin100000000000;

ASSERT z3 = BVPLUS(11,y3,k3);
ASSERT z3 & y3 = y3;


p_z3 : BITVECTOR(2);
ASSERT BVLE( p_z3 , 0bin10);
ASSERT BVGE( p_z3 , 0bin00);
ASSERT p_z3@z3 = BVPLUS( 13, BVMULT( 13, 0bin0000000000011, 0bin00@t0_3 ),0bin00000000000@p_z3);
t_t0_3 : BITVECTOR(3);
ASSERT BVLE( t_t0_3, 0bin111);
ASSERT BVGE( t_t0_3, 0bin000);
ASSERT t_t0_3@t0_3 = BVPLUS( 14 , 0bin000@t1_3, 0bin000@t2_3, 0bin000@t3_3, 0bin000@t4_3,0bin000@t5_3,0bin000@t6_3,0bin000@t7_3,0bin00000000000@t_t0_3);
ASSERT (IF t0_3 = 0bin00000000000 THEN t_t0_3 = 0bin000 ELSE BVGE( t_t0_3 , 0bin000) ENDIF);
ASSERT x0_4 = BVPLUS(11,t1_3,x1_3);
ASSERT x0_4 & t1_3 = t1_3;


ASSERT x1_4 = BVPLUS(11,t2_3,x2_3);
ASSERT x1_4 & t2_3 = t2_3;


ASSERT x2_4 = BVPLUS(11,t3_3,x3_3);
ASSERT x2_4 & t3_3 = t3_3;


ASSERT x3_4 = BVPLUS(11,t4_3,x4_3);
ASSERT x3_4 & t4_3 = t4_3;


ASSERT x4_4 = BVPLUS(11,t5_3,x5_3);
ASSERT x4_4 & t5_3 = t5_3;


ASSERT x5_4 = BVPLUS(11,t6_3,x6_3);
ASSERT x5_4 & t6_3 = t6_3;


ASSERT x6_4 = BVPLUS(11,t7_3,x7_3);
ASSERT x6_4 & t7_3 = t7_3;


t_x0_4 : BITVECTOR(1);
ASSERT t_x0_4@x0_4 = BVPLUS( 12 , 0bin0@x7_5, 0bin0@y4, 0bin00000000000@t_x0_4);
ASSERT t_x0_4@x0_4 /= 0bin100000000000;

ASSERT z4 = BVPLUS(11,y4,k4);
ASSERT z4 & y4 = y4;


p_z4 : BITVECTOR(2);
ASSERT BVLE( p_z4 , 0bin10);
ASSERT BVGE( p_z4 , 0bin00);
ASSERT p_z4@z4 = BVPLUS( 13, BVMULT( 13, 0bin0000000000011, 0bin00@t0_4 ),0bin00000000000@p_z4);
t_t0_4 : BITVECTOR(3);
ASSERT BVLE( t_t0_4, 0bin111);
ASSERT BVGE( t_t0_4, 0bin000);
ASSERT t_t0_4@t0_4 = BVPLUS( 14 , 0bin000@t1_4, 0bin000@t2_4, 0bin000@t3_4, 0bin000@t4_4,0bin000@t5_4,0bin000@t6_4,0bin000@t7_4,0bin00000000000@t_t0_4);
ASSERT (IF t0_4 = 0bin00000000000 THEN t_t0_4 = 0bin000 ELSE BVGE( t_t0_4 , 0bin000) ENDIF);
ASSERT x0_5 = BVPLUS(11,t1_4,x1_4);
ASSERT x0_5 & t1_4 = t1_4;


ASSERT x1_5 = BVPLUS(11,t2_4,x2_4);
ASSERT x1_5 & t2_4 = t2_4;


ASSERT x2_5 = BVPLUS(11,t3_4,x3_4);
ASSERT x2_5 & t3_4 = t3_4;


ASSERT x3_5 = BVPLUS(11,t4_4,x4_4);
ASSERT x3_5 & t4_4 = t4_4;


ASSERT x4_5 = BVPLUS(11,t5_4,x5_4);
ASSERT x4_5 & t5_4 = t5_4;


ASSERT x5_5 = BVPLUS(11,t6_4,x6_4);
ASSERT x5_5 & t6_4 = t6_4;


ASSERT x6_5 = BVPLUS(11,t7_4,x7_4);
ASSERT x6_5 & t7_4 = t7_4;


t_x0_5 : BITVECTOR(1);
ASSERT t_x0_5@x0_5 = BVPLUS( 12 , 0bin0@x7_6, 0bin0@y5, 0bin00000000000@t_x0_5);
ASSERT t_x0_5@x0_5 /= 0bin100000000000;

ASSERT z5 = BVPLUS(11,y5,k5);
ASSERT z5 & y5 = y5;


p_z5 : BITVECTOR(2);
ASSERT BVLE( p_z5 , 0bin10);
ASSERT BVGE( p_z5 , 0bin00);
ASSERT p_z5@z5 = BVPLUS( 13, BVMULT( 13, 0bin0000000000011, 0bin00@t0_5 ),0bin00000000000@p_z5);
t_t0_5 : BITVECTOR(3);
ASSERT BVLE( t_t0_5, 0bin111);
ASSERT BVGE( t_t0_5, 0bin000);
ASSERT t_t0_5@t0_5 = BVPLUS( 14 , 0bin000@t1_5, 0bin000@t2_5, 0bin000@t3_5, 0bin000@t4_5,0bin000@t5_5,0bin000@t6_5,0bin000@t7_5,0bin00000000000@t_t0_5);
ASSERT (IF t0_5 = 0bin00000000000 THEN t_t0_5 = 0bin000 ELSE BVGE( t_t0_5 , 0bin000) ENDIF);
ASSERT x0_6 = BVPLUS(11,t1_5,x1_5);
ASSERT x0_6 & t1_5 = t1_5;


ASSERT x1_6 = BVPLUS(11,t2_5,x2_5);
ASSERT x1_6 & t2_5 = t2_5;


ASSERT x2_6 = BVPLUS(11,t3_5,x3_5);
ASSERT x2_6 & t3_5 = t3_5;


ASSERT x3_6 = BVPLUS(11,t4_5,x4_5);
ASSERT x3_6 & t4_5 = t4_5;


ASSERT x4_6 = BVPLUS(11,t5_5,x5_5);
ASSERT x4_6 & t5_5 = t5_5;


ASSERT x5_6 = BVPLUS(11,t6_5,x6_5);
ASSERT x5_6 & t6_5 = t6_5;


ASSERT x6_6 = BVPLUS(11,t7_5,x7_5);
ASSERT x6_6 & t7_5 = t7_5;


t_x0_6 : BITVECTOR(1);
ASSERT t_x0_6@x0_6 = BVPLUS( 12 , 0bin0@x7_7, 0bin0@y6, 0bin00000000000@t_x0_6);
ASSERT t_x0_6@x0_6 /= 0bin100000000000;

ASSERT z6 = BVPLUS(11,y6,k6);
ASSERT z6 & y6 = y6;


p_z6 : BITVECTOR(2);
ASSERT BVLE( p_z6 , 0bin10);
ASSERT BVGE( p_z6 , 0bin00);
ASSERT p_z6@z6 = BVPLUS( 13, BVMULT( 13, 0bin0000000000011, 0bin00@t0_6 ),0bin00000000000@p_z6);
t_t0_6 : BITVECTOR(3);
ASSERT BVLE( t_t0_6, 0bin111);
ASSERT BVGE( t_t0_6, 0bin000);
ASSERT t_t0_6@t0_6 = BVPLUS( 14 , 0bin000@t1_6, 0bin000@t2_6, 0bin000@t3_6, 0bin000@t4_6,0bin000@t5_6,0bin000@t6_6,0bin000@t7_6,0bin00000000000@t_t0_6);
ASSERT (IF t0_6 = 0bin00000000000 THEN t_t0_6 = 0bin000 ELSE BVGE( t_t0_6 , 0bin000) ENDIF);
ASSERT x0_7 = BVPLUS(11,t1_6,x1_6);
ASSERT x0_7 & t1_6 = t1_6;


ASSERT x1_7 = BVPLUS(11,t2_6,x2_6);
ASSERT x1_7 & t2_6 = t2_6;


ASSERT x2_7 = BVPLUS(11,t3_6,x3_6);
ASSERT x2_7 & t3_6 = t3_6;


ASSERT x3_7 = BVPLUS(11,t4_6,x4_6);
ASSERT x3_7 & t4_6 = t4_6;


ASSERT x4_7 = BVPLUS(11,t5_6,x5_6);
ASSERT x4_7 & t5_6 = t5_6;


ASSERT x5_7 = BVPLUS(11,t6_6,x6_6);
ASSERT x5_7 & t6_6 = t6_6;


ASSERT x6_7 = BVPLUS(11,t7_6,x7_6);
ASSERT x6_7 & t7_6 = t7_6;


ASSERT wk = 0bin00010010;
QUERY FALSE;
COUNTEREXAMPLE;
