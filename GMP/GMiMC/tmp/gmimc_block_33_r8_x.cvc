%Block size: 33
%Round = 8
%Test weight 
x0_0: BITVECTOR(33);
x0_1: BITVECTOR(33);
x0_2: BITVECTOR(33);
x0_3: BITVECTOR(33);
x0_4: BITVECTOR(33);
x0_5: BITVECTOR(33);
x0_6: BITVECTOR(33);
x0_7: BITVECTOR(33);
x0_8: BITVECTOR(33);

x1_0: BITVECTOR(33);
x1_1: BITVECTOR(33);
x1_2: BITVECTOR(33);
x1_3: BITVECTOR(33);
x1_4: BITVECTOR(33);
x1_5: BITVECTOR(33);
x1_6: BITVECTOR(33);
x1_7: BITVECTOR(33);
x1_8: BITVECTOR(33);

x2_0: BITVECTOR(33);
x2_1: BITVECTOR(33);
x2_2: BITVECTOR(33);
x2_3: BITVECTOR(33);
x2_4: BITVECTOR(33);
x2_5: BITVECTOR(33);
x2_6: BITVECTOR(33);
x2_7: BITVECTOR(33);
x2_8: BITVECTOR(33);

x3_0: BITVECTOR(33);
x3_1: BITVECTOR(33);
x3_2: BITVECTOR(33);
x3_3: BITVECTOR(33);
x3_4: BITVECTOR(33);
x3_5: BITVECTOR(33);
x3_6: BITVECTOR(33);
x3_7: BITVECTOR(33);
x3_8: BITVECTOR(33);

x4_0: BITVECTOR(33);
x4_1: BITVECTOR(33);
x4_2: BITVECTOR(33);
x4_3: BITVECTOR(33);
x4_4: BITVECTOR(33);
x4_5: BITVECTOR(33);
x4_6: BITVECTOR(33);
x4_7: BITVECTOR(33);
x4_8: BITVECTOR(33);

x5_0: BITVECTOR(33);
x5_1: BITVECTOR(33);
x5_2: BITVECTOR(33);
x5_3: BITVECTOR(33);
x5_4: BITVECTOR(33);
x5_5: BITVECTOR(33);
x5_6: BITVECTOR(33);
x5_7: BITVECTOR(33);
x5_8: BITVECTOR(33);

x6_0: BITVECTOR(33);
x6_1: BITVECTOR(33);
x6_2: BITVECTOR(33);
x6_3: BITVECTOR(33);
x6_4: BITVECTOR(33);
x6_5: BITVECTOR(33);
x6_6: BITVECTOR(33);
x6_7: BITVECTOR(33);
x6_8: BITVECTOR(33);

x7_0: BITVECTOR(33);
x7_1: BITVECTOR(33);
x7_2: BITVECTOR(33);
x7_3: BITVECTOR(33);
x7_4: BITVECTOR(33);
x7_5: BITVECTOR(33);
x7_6: BITVECTOR(33);
x7_7: BITVECTOR(33);
x7_8: BITVECTOR(33);

k0: BITVECTOR(33);
k1: BITVECTOR(33);
k2: BITVECTOR(33);
k3: BITVECTOR(33);
k4: BITVECTOR(33);
k5: BITVECTOR(33);
k6: BITVECTOR(33);
k7: BITVECTOR(33);

y0: BITVECTOR(33);
y1: BITVECTOR(33);
y2: BITVECTOR(33);
y3: BITVECTOR(33);
y4: BITVECTOR(33);
y5: BITVECTOR(33);
y6: BITVECTOR(33);
y7: BITVECTOR(33);

z0: BITVECTOR(33);
z1: BITVECTOR(33);
z2: BITVECTOR(33);
z3: BITVECTOR(33);
z4: BITVECTOR(33);
z5: BITVECTOR(33);
z6: BITVECTOR(33);
z7: BITVECTOR(33);

t0_0: BITVECTOR(33);
t0_1: BITVECTOR(33);
t0_2: BITVECTOR(33);
t0_3: BITVECTOR(33);
t0_4: BITVECTOR(33);
t0_5: BITVECTOR(33);
t0_6: BITVECTOR(33);
t0_7: BITVECTOR(33);

t1_0: BITVECTOR(33);
t1_1: BITVECTOR(33);
t1_2: BITVECTOR(33);
t1_3: BITVECTOR(33);
t1_4: BITVECTOR(33);
t1_5: BITVECTOR(33);
t1_6: BITVECTOR(33);
t1_7: BITVECTOR(33);

t2_0: BITVECTOR(33);
t2_1: BITVECTOR(33);
t2_2: BITVECTOR(33);
t2_3: BITVECTOR(33);
t2_4: BITVECTOR(33);
t2_5: BITVECTOR(33);
t2_6: BITVECTOR(33);
t2_7: BITVECTOR(33);

t3_0: BITVECTOR(33);
t3_1: BITVECTOR(33);
t3_2: BITVECTOR(33);
t3_3: BITVECTOR(33);
t3_4: BITVECTOR(33);
t3_5: BITVECTOR(33);
t3_6: BITVECTOR(33);
t3_7: BITVECTOR(33);

t4_0: BITVECTOR(33);
t4_1: BITVECTOR(33);
t4_2: BITVECTOR(33);
t4_3: BITVECTOR(33);
t4_4: BITVECTOR(33);
t4_5: BITVECTOR(33);
t4_6: BITVECTOR(33);
t4_7: BITVECTOR(33);

t5_0: BITVECTOR(33);
t5_1: BITVECTOR(33);
t5_2: BITVECTOR(33);
t5_3: BITVECTOR(33);
t5_4: BITVECTOR(33);
t5_5: BITVECTOR(33);
t5_6: BITVECTOR(33);
t5_7: BITVECTOR(33);

t6_0: BITVECTOR(33);
t6_1: BITVECTOR(33);
t6_2: BITVECTOR(33);
t6_3: BITVECTOR(33);
t6_4: BITVECTOR(33);
t6_5: BITVECTOR(33);
t6_6: BITVECTOR(33);
t6_7: BITVECTOR(33);

t7_0: BITVECTOR(33);
t7_1: BITVECTOR(33);
t7_2: BITVECTOR(33);
t7_3: BITVECTOR(33);
t7_4: BITVECTOR(33);
t7_5: BITVECTOR(33);
t7_6: BITVECTOR(33);
t7_7: BITVECTOR(33);


wk0 : BITVECTOR(10);
ASSERT wk0 = BVPLUS(10,0bin000000000@(k0[0:0]),0bin000000000@(k0[1:1]),0bin000000000@(k0[2:2]),0bin000000000@(k0[3:3]),0bin000000000@(k0[4:4]),0bin000000000@(k0[5:5]),0bin000000000@(k0[6:6]),0bin000000000@(k0[7:7]),0bin000000000@(k0[8:8]),0bin000000000@(k0[9:9]),0bin000000000@(k0[10:10]),0bin000000000@(k0[11:11]),0bin000000000@(k0[12:12]),0bin000000000@(k0[13:13]),0bin000000000@(k0[14:14]),0bin000000000@(k0[15:15]),0bin000000000@(k0[16:16]),0bin000000000@(k0[17:17]),0bin000000000@(k0[18:18]),0bin000000000@(k0[19:19]),0bin000000000@(k0[20:20]),0bin000000000@(k0[21:21]),0bin000000000@(k0[22:22]),0bin000000000@(k0[23:23]),0bin000000000@(k0[24:24]),0bin000000000@(k0[25:25]),0bin000000000@(k0[26:26]),0bin000000000@(k0[27:27]),0bin000000000@(k0[28:28]),0bin000000000@(k0[29:29]),0bin000000000@(k0[30:30]),0bin000000000@(k0[31:31]),0bin000000000@(k0[32:32]));


wk1 : BITVECTOR(10);
ASSERT wk1 = BVPLUS(10,0bin000000000@(k1[0:0]),0bin000000000@(k1[1:1]),0bin000000000@(k1[2:2]),0bin000000000@(k1[3:3]),0bin000000000@(k1[4:4]),0bin000000000@(k1[5:5]),0bin000000000@(k1[6:6]),0bin000000000@(k1[7:7]),0bin000000000@(k1[8:8]),0bin000000000@(k1[9:9]),0bin000000000@(k1[10:10]),0bin000000000@(k1[11:11]),0bin000000000@(k1[12:12]),0bin000000000@(k1[13:13]),0bin000000000@(k1[14:14]),0bin000000000@(k1[15:15]),0bin000000000@(k1[16:16]),0bin000000000@(k1[17:17]),0bin000000000@(k1[18:18]),0bin000000000@(k1[19:19]),0bin000000000@(k1[20:20]),0bin000000000@(k1[21:21]),0bin000000000@(k1[22:22]),0bin000000000@(k1[23:23]),0bin000000000@(k1[24:24]),0bin000000000@(k1[25:25]),0bin000000000@(k1[26:26]),0bin000000000@(k1[27:27]),0bin000000000@(k1[28:28]),0bin000000000@(k1[29:29]),0bin000000000@(k1[30:30]),0bin000000000@(k1[31:31]),0bin000000000@(k1[32:32]));


wk2 : BITVECTOR(10);
ASSERT wk2 = BVPLUS(10,0bin000000000@(k2[0:0]),0bin000000000@(k2[1:1]),0bin000000000@(k2[2:2]),0bin000000000@(k2[3:3]),0bin000000000@(k2[4:4]),0bin000000000@(k2[5:5]),0bin000000000@(k2[6:6]),0bin000000000@(k2[7:7]),0bin000000000@(k2[8:8]),0bin000000000@(k2[9:9]),0bin000000000@(k2[10:10]),0bin000000000@(k2[11:11]),0bin000000000@(k2[12:12]),0bin000000000@(k2[13:13]),0bin000000000@(k2[14:14]),0bin000000000@(k2[15:15]),0bin000000000@(k2[16:16]),0bin000000000@(k2[17:17]),0bin000000000@(k2[18:18]),0bin000000000@(k2[19:19]),0bin000000000@(k2[20:20]),0bin000000000@(k2[21:21]),0bin000000000@(k2[22:22]),0bin000000000@(k2[23:23]),0bin000000000@(k2[24:24]),0bin000000000@(k2[25:25]),0bin000000000@(k2[26:26]),0bin000000000@(k2[27:27]),0bin000000000@(k2[28:28]),0bin000000000@(k2[29:29]),0bin000000000@(k2[30:30]),0bin000000000@(k2[31:31]),0bin000000000@(k2[32:32]));


wk3 : BITVECTOR(10);
ASSERT wk3 = BVPLUS(10,0bin000000000@(k3[0:0]),0bin000000000@(k3[1:1]),0bin000000000@(k3[2:2]),0bin000000000@(k3[3:3]),0bin000000000@(k3[4:4]),0bin000000000@(k3[5:5]),0bin000000000@(k3[6:6]),0bin000000000@(k3[7:7]),0bin000000000@(k3[8:8]),0bin000000000@(k3[9:9]),0bin000000000@(k3[10:10]),0bin000000000@(k3[11:11]),0bin000000000@(k3[12:12]),0bin000000000@(k3[13:13]),0bin000000000@(k3[14:14]),0bin000000000@(k3[15:15]),0bin000000000@(k3[16:16]),0bin000000000@(k3[17:17]),0bin000000000@(k3[18:18]),0bin000000000@(k3[19:19]),0bin000000000@(k3[20:20]),0bin000000000@(k3[21:21]),0bin000000000@(k3[22:22]),0bin000000000@(k3[23:23]),0bin000000000@(k3[24:24]),0bin000000000@(k3[25:25]),0bin000000000@(k3[26:26]),0bin000000000@(k3[27:27]),0bin000000000@(k3[28:28]),0bin000000000@(k3[29:29]),0bin000000000@(k3[30:30]),0bin000000000@(k3[31:31]),0bin000000000@(k3[32:32]));


wk4 : BITVECTOR(10);
ASSERT wk4 = BVPLUS(10,0bin000000000@(k4[0:0]),0bin000000000@(k4[1:1]),0bin000000000@(k4[2:2]),0bin000000000@(k4[3:3]),0bin000000000@(k4[4:4]),0bin000000000@(k4[5:5]),0bin000000000@(k4[6:6]),0bin000000000@(k4[7:7]),0bin000000000@(k4[8:8]),0bin000000000@(k4[9:9]),0bin000000000@(k4[10:10]),0bin000000000@(k4[11:11]),0bin000000000@(k4[12:12]),0bin000000000@(k4[13:13]),0bin000000000@(k4[14:14]),0bin000000000@(k4[15:15]),0bin000000000@(k4[16:16]),0bin000000000@(k4[17:17]),0bin000000000@(k4[18:18]),0bin000000000@(k4[19:19]),0bin000000000@(k4[20:20]),0bin000000000@(k4[21:21]),0bin000000000@(k4[22:22]),0bin000000000@(k4[23:23]),0bin000000000@(k4[24:24]),0bin000000000@(k4[25:25]),0bin000000000@(k4[26:26]),0bin000000000@(k4[27:27]),0bin000000000@(k4[28:28]),0bin000000000@(k4[29:29]),0bin000000000@(k4[30:30]),0bin000000000@(k4[31:31]),0bin000000000@(k4[32:32]));


wk5 : BITVECTOR(10);
ASSERT wk5 = BVPLUS(10,0bin000000000@(k5[0:0]),0bin000000000@(k5[1:1]),0bin000000000@(k5[2:2]),0bin000000000@(k5[3:3]),0bin000000000@(k5[4:4]),0bin000000000@(k5[5:5]),0bin000000000@(k5[6:6]),0bin000000000@(k5[7:7]),0bin000000000@(k5[8:8]),0bin000000000@(k5[9:9]),0bin000000000@(k5[10:10]),0bin000000000@(k5[11:11]),0bin000000000@(k5[12:12]),0bin000000000@(k5[13:13]),0bin000000000@(k5[14:14]),0bin000000000@(k5[15:15]),0bin000000000@(k5[16:16]),0bin000000000@(k5[17:17]),0bin000000000@(k5[18:18]),0bin000000000@(k5[19:19]),0bin000000000@(k5[20:20]),0bin000000000@(k5[21:21]),0bin000000000@(k5[22:22]),0bin000000000@(k5[23:23]),0bin000000000@(k5[24:24]),0bin000000000@(k5[25:25]),0bin000000000@(k5[26:26]),0bin000000000@(k5[27:27]),0bin000000000@(k5[28:28]),0bin000000000@(k5[29:29]),0bin000000000@(k5[30:30]),0bin000000000@(k5[31:31]),0bin000000000@(k5[32:32]));


wk6 : BITVECTOR(10);
ASSERT wk6 = BVPLUS(10,0bin000000000@(k6[0:0]),0bin000000000@(k6[1:1]),0bin000000000@(k6[2:2]),0bin000000000@(k6[3:3]),0bin000000000@(k6[4:4]),0bin000000000@(k6[5:5]),0bin000000000@(k6[6:6]),0bin000000000@(k6[7:7]),0bin000000000@(k6[8:8]),0bin000000000@(k6[9:9]),0bin000000000@(k6[10:10]),0bin000000000@(k6[11:11]),0bin000000000@(k6[12:12]),0bin000000000@(k6[13:13]),0bin000000000@(k6[14:14]),0bin000000000@(k6[15:15]),0bin000000000@(k6[16:16]),0bin000000000@(k6[17:17]),0bin000000000@(k6[18:18]),0bin000000000@(k6[19:19]),0bin000000000@(k6[20:20]),0bin000000000@(k6[21:21]),0bin000000000@(k6[22:22]),0bin000000000@(k6[23:23]),0bin000000000@(k6[24:24]),0bin000000000@(k6[25:25]),0bin000000000@(k6[26:26]),0bin000000000@(k6[27:27]),0bin000000000@(k6[28:28]),0bin000000000@(k6[29:29]),0bin000000000@(k6[30:30]),0bin000000000@(k6[31:31]),0bin000000000@(k6[32:32]));


wk7 : BITVECTOR(10);
ASSERT wk7 = BVPLUS(10,0bin000000000@(k7[0:0]),0bin000000000@(k7[1:1]),0bin000000000@(k7[2:2]),0bin000000000@(k7[3:3]),0bin000000000@(k7[4:4]),0bin000000000@(k7[5:5]),0bin000000000@(k7[6:6]),0bin000000000@(k7[7:7]),0bin000000000@(k7[8:8]),0bin000000000@(k7[9:9]),0bin000000000@(k7[10:10]),0bin000000000@(k7[11:11]),0bin000000000@(k7[12:12]),0bin000000000@(k7[13:13]),0bin000000000@(k7[14:14]),0bin000000000@(k7[15:15]),0bin000000000@(k7[16:16]),0bin000000000@(k7[17:17]),0bin000000000@(k7[18:18]),0bin000000000@(k7[19:19]),0bin000000000@(k7[20:20]),0bin000000000@(k7[21:21]),0bin000000000@(k7[22:22]),0bin000000000@(k7[23:23]),0bin000000000@(k7[24:24]),0bin000000000@(k7[25:25]),0bin000000000@(k7[26:26]),0bin000000000@(k7[27:27]),0bin000000000@(k7[28:28]),0bin000000000@(k7[29:29]),0bin000000000@(k7[30:30]),0bin000000000@(k7[31:31]),0bin000000000@(k7[32:32]));


wk : BITVECTOR(10);
ASSERT wk = BVPLUS(10, wk0, wk1, wk2, wk3, wk4, wk5, wk6, wk7);


wx0 : BITVECTOR(9);
ASSERT wx0 = BVPLUS(9,0bin00000000@(x0_0[0:0]),0bin00000000@(x0_0[1:1]),0bin00000000@(x0_0[2:2]),0bin00000000@(x0_0[3:3]),0bin00000000@(x0_0[4:4]),0bin00000000@(x0_0[5:5]),0bin00000000@(x0_0[6:6]),0bin00000000@(x0_0[7:7]),0bin00000000@(x0_0[8:8]),0bin00000000@(x0_0[9:9]),0bin00000000@(x0_0[10:10]),0bin00000000@(x0_0[11:11]),0bin00000000@(x0_0[12:12]),0bin00000000@(x0_0[13:13]),0bin00000000@(x0_0[14:14]),0bin00000000@(x0_0[15:15]),0bin00000000@(x0_0[16:16]),0bin00000000@(x0_0[17:17]),0bin00000000@(x0_0[18:18]),0bin00000000@(x0_0[19:19]),0bin00000000@(x0_0[20:20]),0bin00000000@(x0_0[21:21]),0bin00000000@(x0_0[22:22]),0bin00000000@(x0_0[23:23]),0bin00000000@(x0_0[24:24]),0bin00000000@(x0_0[25:25]),0bin00000000@(x0_0[26:26]),0bin00000000@(x0_0[27:27]),0bin00000000@(x0_0[28:28]),0bin00000000@(x0_0[29:29]),0bin00000000@(x0_0[30:30]),0bin00000000@(x0_0[31:31]),0bin00000000@(x0_0[32:32]));


wx1: BITVECTOR(9);
ASSERT wx1 = BVPLUS(9,0bin00000000@(x1_0[0:0]),0bin00000000@(x1_0[1:1]),0bin00000000@(x1_0[2:2]),0bin00000000@(x1_0[3:3]),0bin00000000@(x1_0[4:4]),0bin00000000@(x1_0[5:5]),0bin00000000@(x1_0[6:6]),0bin00000000@(x1_0[7:7]),0bin00000000@(x1_0[8:8]),0bin00000000@(x1_0[9:9]),0bin00000000@(x1_0[10:10]),0bin00000000@(x1_0[11:11]),0bin00000000@(x1_0[12:12]),0bin00000000@(x1_0[13:13]),0bin00000000@(x1_0[14:14]),0bin00000000@(x1_0[15:15]),0bin00000000@(x1_0[16:16]),0bin00000000@(x1_0[17:17]),0bin00000000@(x1_0[18:18]),0bin00000000@(x1_0[19:19]),0bin00000000@(x1_0[20:20]),0bin00000000@(x1_0[21:21]),0bin00000000@(x1_0[22:22]),0bin00000000@(x1_0[23:23]),0bin00000000@(x1_0[24:24]),0bin00000000@(x1_0[25:25]),0bin00000000@(x1_0[26:26]),0bin00000000@(x1_0[27:27]),0bin00000000@(x1_0[28:28]),0bin00000000@(x1_0[29:29]),0bin00000000@(x1_0[30:30]),0bin00000000@(x1_0[31:31]),0bin00000000@(x1_0[32:32]));


wx2: BITVECTOR(9);
ASSERT wx2 = BVPLUS(9,0bin00000000@(x2_0[0:0]),0bin00000000@(x2_0[1:1]),0bin00000000@(x2_0[2:2]),0bin00000000@(x2_0[3:3]),0bin00000000@(x2_0[4:4]),0bin00000000@(x2_0[5:5]),0bin00000000@(x2_0[6:6]),0bin00000000@(x2_0[7:7]),0bin00000000@(x2_0[8:8]),0bin00000000@(x2_0[9:9]),0bin00000000@(x2_0[10:10]),0bin00000000@(x2_0[11:11]),0bin00000000@(x2_0[12:12]),0bin00000000@(x2_0[13:13]),0bin00000000@(x2_0[14:14]),0bin00000000@(x2_0[15:15]),0bin00000000@(x2_0[16:16]),0bin00000000@(x2_0[17:17]),0bin00000000@(x2_0[18:18]),0bin00000000@(x2_0[19:19]),0bin00000000@(x2_0[20:20]),0bin00000000@(x2_0[21:21]),0bin00000000@(x2_0[22:22]),0bin00000000@(x2_0[23:23]),0bin00000000@(x2_0[24:24]),0bin00000000@(x2_0[25:25]),0bin00000000@(x2_0[26:26]),0bin00000000@(x2_0[27:27]),0bin00000000@(x2_0[28:28]),0bin00000000@(x2_0[29:29]),0bin00000000@(x2_0[30:30]),0bin00000000@(x2_0[31:31]),0bin00000000@(x2_0[32:32]));


wx3: BITVECTOR(9);
ASSERT wx3 = BVPLUS(9,0bin00000000@(x3_0[0:0]),0bin00000000@(x3_0[1:1]),0bin00000000@(x3_0[2:2]),0bin00000000@(x3_0[3:3]),0bin00000000@(x3_0[4:4]),0bin00000000@(x3_0[5:5]),0bin00000000@(x3_0[6:6]),0bin00000000@(x3_0[7:7]),0bin00000000@(x3_0[8:8]),0bin00000000@(x3_0[9:9]),0bin00000000@(x3_0[10:10]),0bin00000000@(x3_0[11:11]),0bin00000000@(x3_0[12:12]),0bin00000000@(x3_0[13:13]),0bin00000000@(x3_0[14:14]),0bin00000000@(x3_0[15:15]),0bin00000000@(x3_0[16:16]),0bin00000000@(x3_0[17:17]),0bin00000000@(x3_0[18:18]),0bin00000000@(x3_0[19:19]),0bin00000000@(x3_0[20:20]),0bin00000000@(x3_0[21:21]),0bin00000000@(x3_0[22:22]),0bin00000000@(x3_0[23:23]),0bin00000000@(x3_0[24:24]),0bin00000000@(x3_0[25:25]),0bin00000000@(x3_0[26:26]),0bin00000000@(x3_0[27:27]),0bin00000000@(x3_0[28:28]),0bin00000000@(x3_0[29:29]),0bin00000000@(x3_0[30:30]),0bin00000000@(x3_0[31:31]),0bin00000000@(x3_0[32:32]));


wx4 : BITVECTOR(9);
ASSERT wx4 = BVPLUS(9,0bin00000000@(x4_0[0:0]),0bin00000000@(x4_0[1:1]),0bin00000000@(x4_0[2:2]),0bin00000000@(x4_0[3:3]),0bin00000000@(x4_0[4:4]),0bin00000000@(x4_0[5:5]),0bin00000000@(x4_0[6:6]),0bin00000000@(x4_0[7:7]),0bin00000000@(x4_0[8:8]),0bin00000000@(x4_0[9:9]),0bin00000000@(x4_0[10:10]),0bin00000000@(x4_0[11:11]),0bin00000000@(x4_0[12:12]),0bin00000000@(x4_0[13:13]),0bin00000000@(x4_0[14:14]),0bin00000000@(x4_0[15:15]),0bin00000000@(x4_0[16:16]),0bin00000000@(x4_0[17:17]),0bin00000000@(x4_0[18:18]),0bin00000000@(x4_0[19:19]),0bin00000000@(x4_0[20:20]),0bin00000000@(x4_0[21:21]),0bin00000000@(x4_0[22:22]),0bin00000000@(x4_0[23:23]),0bin00000000@(x4_0[24:24]),0bin00000000@(x4_0[25:25]),0bin00000000@(x4_0[26:26]),0bin00000000@(x4_0[27:27]),0bin00000000@(x4_0[28:28]),0bin00000000@(x4_0[29:29]),0bin00000000@(x4_0[30:30]),0bin00000000@(x4_0[31:31]),0bin00000000@(x4_0[32:32]));


wx5: BITVECTOR(9);
ASSERT wx5 = BVPLUS(9,0bin00000000@(x5_0[0:0]),0bin00000000@(x5_0[1:1]),0bin00000000@(x5_0[2:2]),0bin00000000@(x5_0[3:3]),0bin00000000@(x5_0[4:4]),0bin00000000@(x5_0[5:5]),0bin00000000@(x5_0[6:6]),0bin00000000@(x5_0[7:7]),0bin00000000@(x5_0[8:8]),0bin00000000@(x5_0[9:9]),0bin00000000@(x5_0[10:10]),0bin00000000@(x5_0[11:11]),0bin00000000@(x5_0[12:12]),0bin00000000@(x5_0[13:13]),0bin00000000@(x5_0[14:14]),0bin00000000@(x5_0[15:15]),0bin00000000@(x5_0[16:16]),0bin00000000@(x5_0[17:17]),0bin00000000@(x5_0[18:18]),0bin00000000@(x5_0[19:19]),0bin00000000@(x5_0[20:20]),0bin00000000@(x5_0[21:21]),0bin00000000@(x5_0[22:22]),0bin00000000@(x5_0[23:23]),0bin00000000@(x5_0[24:24]),0bin00000000@(x5_0[25:25]),0bin00000000@(x5_0[26:26]),0bin00000000@(x5_0[27:27]),0bin00000000@(x5_0[28:28]),0bin00000000@(x5_0[29:29]),0bin00000000@(x5_0[30:30]),0bin00000000@(x5_0[31:31]),0bin00000000@(x5_0[32:32]));


wx6: BITVECTOR(9);
ASSERT wx6 = BVPLUS(9,0bin00000000@(x6_0[0:0]),0bin00000000@(x6_0[1:1]),0bin00000000@(x6_0[2:2]),0bin00000000@(x6_0[3:3]),0bin00000000@(x6_0[4:4]),0bin00000000@(x6_0[5:5]),0bin00000000@(x6_0[6:6]),0bin00000000@(x6_0[7:7]),0bin00000000@(x6_0[8:8]),0bin00000000@(x6_0[9:9]),0bin00000000@(x6_0[10:10]),0bin00000000@(x6_0[11:11]),0bin00000000@(x6_0[12:12]),0bin00000000@(x6_0[13:13]),0bin00000000@(x6_0[14:14]),0bin00000000@(x6_0[15:15]),0bin00000000@(x6_0[16:16]),0bin00000000@(x6_0[17:17]),0bin00000000@(x6_0[18:18]),0bin00000000@(x6_0[19:19]),0bin00000000@(x6_0[20:20]),0bin00000000@(x6_0[21:21]),0bin00000000@(x6_0[22:22]),0bin00000000@(x6_0[23:23]),0bin00000000@(x6_0[24:24]),0bin00000000@(x6_0[25:25]),0bin00000000@(x6_0[26:26]),0bin00000000@(x6_0[27:27]),0bin00000000@(x6_0[28:28]),0bin00000000@(x6_0[29:29]),0bin00000000@(x6_0[30:30]),0bin00000000@(x6_0[31:31]),0bin00000000@(x6_0[32:32]));


wx7: BITVECTOR(9);
ASSERT wx7 = BVPLUS(9,0bin00000000@(x7_0[0:0]),0bin00000000@(x7_0[1:1]),0bin00000000@(x7_0[2:2]),0bin00000000@(x7_0[3:3]),0bin00000000@(x7_0[4:4]),0bin00000000@(x7_0[5:5]),0bin00000000@(x7_0[6:6]),0bin00000000@(x7_0[7:7]),0bin00000000@(x7_0[8:8]),0bin00000000@(x7_0[9:9]),0bin00000000@(x7_0[10:10]),0bin00000000@(x7_0[11:11]),0bin00000000@(x7_0[12:12]),0bin00000000@(x7_0[13:13]),0bin00000000@(x7_0[14:14]),0bin00000000@(x7_0[15:15]),0bin00000000@(x7_0[16:16]),0bin00000000@(x7_0[17:17]),0bin00000000@(x7_0[18:18]),0bin00000000@(x7_0[19:19]),0bin00000000@(x7_0[20:20]),0bin00000000@(x7_0[21:21]),0bin00000000@(x7_0[22:22]),0bin00000000@(x7_0[23:23]),0bin00000000@(x7_0[24:24]),0bin00000000@(x7_0[25:25]),0bin00000000@(x7_0[26:26]),0bin00000000@(x7_0[27:27]),0bin00000000@(x7_0[28:28]),0bin00000000@(x7_0[29:29]),0bin00000000@(x7_0[30:30]),0bin00000000@(x7_0[31:31]),0bin00000000@(x7_0[32:32]));


wx : BITVECTOR(9);
ASSERT wx = BVPLUS(9, wx0, wx1, wx2, wx3, wx4, wx5, wx6, wx7);


wx567 : BITVECTOR(9);
ASSERT wx567 = BVPLUS(9, wx5 , wx6 , wx7 );


ASSERT BVLE( x0_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x1_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x2_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x3_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x4_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x5_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x6_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x7_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( x0_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x1_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x2_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x3_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x4_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x5_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x6_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x7_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( x0_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( x1_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( x2_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( x3_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( x4_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( x5_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( x6_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( x7_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( x0_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( x1_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( x2_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( x3_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( x4_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( x5_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( x6_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( x7_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( x0_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( x1_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( x2_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( x3_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( x4_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( x5_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( x6_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( x7_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( x0_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( x1_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( x2_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( x3_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( x4_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( x5_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( x6_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( x7_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( x0_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( x1_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( x2_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( x3_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( x4_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( x5_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( x6_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( x7_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( x0_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( x1_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( x2_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( x3_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( x4_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( x5_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( x6_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( x7_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( x0_8, 0bin111111111111111111111111111111111);
ASSERT BVLE( x1_8, 0bin111111111111111111111111111111111);
ASSERT BVLE( x2_8, 0bin111111111111111111111111111111111);
ASSERT BVLE( x3_8, 0bin111111111111111111111111111111111);
ASSERT BVLE( x4_8, 0bin111111111111111111111111111111111);
ASSERT BVLE( x5_8, 0bin111111111111111111111111111111111);
ASSERT BVLE( x6_8, 0bin111111111111111111111111111111111);
ASSERT BVLE( x7_8, 0bin111111111111111111111111111111111);
ASSERT BVLE( k0, 0bin111111111111111111111111111111111);
ASSERT BVLE( y0, 0bin111111111111111111111111111111111);
ASSERT BVLE( z0, 0bin111111111111111111111111111111111);
ASSERT BVLE( k1, 0bin111111111111111111111111111111111);
ASSERT BVLE( y1, 0bin111111111111111111111111111111111);
ASSERT BVLE( z1, 0bin111111111111111111111111111111111);
ASSERT BVLE( k2, 0bin111111111111111111111111111111111);
ASSERT BVLE( y2, 0bin111111111111111111111111111111111);
ASSERT BVLE( z2, 0bin111111111111111111111111111111111);
ASSERT BVLE( k3, 0bin111111111111111111111111111111111);
ASSERT BVLE( y3, 0bin111111111111111111111111111111111);
ASSERT BVLE( z3, 0bin111111111111111111111111111111111);
ASSERT BVLE( k4, 0bin111111111111111111111111111111111);
ASSERT BVLE( y4, 0bin111111111111111111111111111111111);
ASSERT BVLE( z4, 0bin111111111111111111111111111111111);
ASSERT BVLE( k5, 0bin111111111111111111111111111111111);
ASSERT BVLE( y5, 0bin111111111111111111111111111111111);
ASSERT BVLE( z5, 0bin111111111111111111111111111111111);
ASSERT BVLE( k6, 0bin111111111111111111111111111111111);
ASSERT BVLE( y6, 0bin111111111111111111111111111111111);
ASSERT BVLE( z6, 0bin111111111111111111111111111111111);
ASSERT BVLE( k7, 0bin111111111111111111111111111111111);
ASSERT BVLE( y7, 0bin111111111111111111111111111111111);
ASSERT BVLE( z7, 0bin111111111111111111111111111111111);
ASSERT BVLE( t0_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t1_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t2_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t3_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t4_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t5_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t6_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t7_0, 0bin111111111111111111111111111111111);
ASSERT BVLE( t0_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( t1_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( t2_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( t3_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( t4_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( t5_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( t6_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( t7_1, 0bin111111111111111111111111111111111);
ASSERT BVLE( t0_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( t1_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( t2_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( t3_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( t4_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( t5_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( t6_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( t7_2, 0bin111111111111111111111111111111111);
ASSERT BVLE( t0_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( t1_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( t2_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( t3_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( t4_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( t5_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( t6_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( t7_3, 0bin111111111111111111111111111111111);
ASSERT BVLE( t0_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( t1_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( t2_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( t3_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( t4_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( t5_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( t6_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( t7_4, 0bin111111111111111111111111111111111);
ASSERT BVLE( t0_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( t1_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( t2_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( t3_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( t4_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( t5_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( t6_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( t7_5, 0bin111111111111111111111111111111111);
ASSERT BVLE( t0_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( t1_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( t2_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( t3_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( t4_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( t5_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( t6_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( t7_6, 0bin111111111111111111111111111111111);
ASSERT BVLE( t0_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( t1_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( t2_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( t3_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( t4_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( t5_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( t6_7, 0bin111111111111111111111111111111111);
ASSERT BVLE( t7_7, 0bin111111111111111111111111111111111);

ASSERT BVGE( x0_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x1_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x2_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x3_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x4_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x5_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x6_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x7_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( x0_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x1_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x2_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x3_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x4_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x5_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x6_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x7_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( x0_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( x1_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( x2_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( x3_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( x4_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( x5_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( x6_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( x7_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( x0_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( x1_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( x2_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( x3_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( x4_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( x5_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( x6_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( x7_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( x0_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( x1_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( x2_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( x3_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( x4_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( x5_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( x6_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( x7_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( x0_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( x1_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( x2_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( x3_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( x4_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( x5_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( x6_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( x7_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( x0_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( x1_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( x2_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( x3_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( x4_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( x5_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( x6_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( x7_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( x0_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( x1_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( x2_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( x3_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( x4_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( x5_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( x6_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( x7_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( x0_8, 0bin000000000000000000000000000000000);
ASSERT BVGE( x1_8, 0bin000000000000000000000000000000000);
ASSERT BVGE( x2_8, 0bin000000000000000000000000000000000);
ASSERT BVGE( x3_8, 0bin000000000000000000000000000000000);
ASSERT BVGE( x4_8, 0bin000000000000000000000000000000000);
ASSERT BVGE( x5_8, 0bin000000000000000000000000000000000);
ASSERT BVGE( x6_8, 0bin000000000000000000000000000000000);
ASSERT BVGE( x7_8, 0bin000000000000000000000000000000000);
ASSERT BVGE( k0, 0bin000000000000000000000000000000000);
ASSERT BVGE( y0, 0bin000000000000000000000000000000000);
ASSERT BVGE( z0, 0bin000000000000000000000000000000000);
ASSERT BVGE( k1, 0bin000000000000000000000000000000000);
ASSERT BVGE( y1, 0bin000000000000000000000000000000000);
ASSERT BVGE( z1, 0bin000000000000000000000000000000000);
ASSERT BVGE( k2, 0bin000000000000000000000000000000000);
ASSERT BVGE( y2, 0bin000000000000000000000000000000000);
ASSERT BVGE( z2, 0bin000000000000000000000000000000000);
ASSERT BVGE( k3, 0bin000000000000000000000000000000000);
ASSERT BVGE( y3, 0bin000000000000000000000000000000000);
ASSERT BVGE( z3, 0bin000000000000000000000000000000000);
ASSERT BVGE( k4, 0bin000000000000000000000000000000000);
ASSERT BVGE( y4, 0bin000000000000000000000000000000000);
ASSERT BVGE( z4, 0bin000000000000000000000000000000000);
ASSERT BVGE( k5, 0bin000000000000000000000000000000000);
ASSERT BVGE( y5, 0bin000000000000000000000000000000000);
ASSERT BVGE( z5, 0bin000000000000000000000000000000000);
ASSERT BVGE( k6, 0bin000000000000000000000000000000000);
ASSERT BVGE( y6, 0bin000000000000000000000000000000000);
ASSERT BVGE( z6, 0bin000000000000000000000000000000000);
ASSERT BVGE( k7, 0bin000000000000000000000000000000000);
ASSERT BVGE( y7, 0bin000000000000000000000000000000000);
ASSERT BVGE( z7, 0bin000000000000000000000000000000000);
ASSERT BVGE( t0_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t1_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t2_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t3_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t4_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t5_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t6_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t7_0, 0bin000000000000000000000000000000000);
ASSERT BVGE( t0_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( t1_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( t2_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( t3_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( t4_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( t5_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( t6_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( t7_1, 0bin000000000000000000000000000000000);
ASSERT BVGE( t0_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( t1_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( t2_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( t3_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( t4_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( t5_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( t6_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( t7_2, 0bin000000000000000000000000000000000);
ASSERT BVGE( t0_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( t1_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( t2_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( t3_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( t4_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( t5_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( t6_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( t7_3, 0bin000000000000000000000000000000000);
ASSERT BVGE( t0_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( t1_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( t2_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( t3_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( t4_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( t5_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( t6_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( t7_4, 0bin000000000000000000000000000000000);
ASSERT BVGE( t0_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( t1_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( t2_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( t3_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( t4_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( t5_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( t6_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( t7_5, 0bin000000000000000000000000000000000);
ASSERT BVGE( t0_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( t1_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( t2_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( t3_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( t4_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( t5_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( t6_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( t7_6, 0bin000000000000000000000000000000000);
ASSERT BVGE( t0_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( t1_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( t2_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( t3_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( t4_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( t5_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( t6_7, 0bin000000000000000000000000000000000);
ASSERT BVGE( t7_7, 0bin000000000000000000000000000000000);

ASSERT x0_8 = 0bin000000000000000000000000000000001;

ASSERT x1_8 = 0bin000000000000000000000000000000000;

ASSERT x2_8 = 0bin000000000000000000000000000000000;

ASSERT x3_8 = 0bin000000000000000000000000000000000;

ASSERT x4_8 = 0bin000000000000000000000000000000000;

ASSERT x5_8 = 0bin000000000000000000000000000000000;

ASSERT x6_8 = 0bin000000000000000000000000000000000;

ASSERT x7_8 = 0bin000000000000000000000000000000000;

t_x0_0 : BITVECTOR(1);
ASSERT t_x0_0@x0_0 = BVPLUS( 34 , 0bin0@x7_1, 0bin0@y0, 0bin000000000000000000000000000000000@t_x0_0);
ASSERT t_x0_0@x0_0 /= 0bin1000000000000000000000000000000000;

ASSERT z0 = BVPLUS(33,y0,k0);
ASSERT z0 & y0 = y0;


p_z0 : BITVECTOR(2);
ASSERT BVLE( p_z0 , 0bin10);
ASSERT BVGE( p_z0 , 0bin00);
ASSERT p_z0@z0 = BVPLUS( 35, BVMULT( 35, 0bin00000000000000000000000000000000011, 0bin00@t0_0 ),0bin000000000000000000000000000000000@p_z0);
t_t0_0 : BITVECTOR(3);
ASSERT BVLE( t_t0_0, 0bin111);
ASSERT BVGE( t_t0_0, 0bin000);
ASSERT t_t0_0@t0_0 = BVPLUS( 36 , 0bin000@t1_0, 0bin000@t2_0, 0bin000@t3_0, 0bin000@t4_0,0bin000@t5_0,0bin000@t6_0,0bin000@t7_0,0bin000000000000000000000000000000000@t_t0_0);
ASSERT (IF t0_0 = 0bin000000000000000000000000000000000 THEN t_t0_0 = 0bin000 ELSE BVGE( t_t0_0 , 0bin000) ENDIF);
ASSERT x0_1 = BVPLUS(33,t1_0,x1_0);
ASSERT x0_1 & t1_0 = t1_0;


ASSERT x1_1 = BVPLUS(33,t2_0,x2_0);
ASSERT x1_1 & t2_0 = t2_0;


ASSERT x2_1 = BVPLUS(33,t3_0,x3_0);
ASSERT x2_1 & t3_0 = t3_0;


ASSERT x3_1 = BVPLUS(33,t4_0,x4_0);
ASSERT x3_1 & t4_0 = t4_0;


ASSERT x4_1 = BVPLUS(33,t5_0,x5_0);
ASSERT x4_1 & t5_0 = t5_0;


ASSERT x5_1 = BVPLUS(33,t6_0,x6_0);
ASSERT x5_1 & t6_0 = t6_0;


ASSERT x6_1 = BVPLUS(33,t7_0,x7_0);
ASSERT x6_1 & t7_0 = t7_0;


t_x0_1 : BITVECTOR(1);
ASSERT t_x0_1@x0_1 = BVPLUS( 34 , 0bin0@x7_2, 0bin0@y1, 0bin000000000000000000000000000000000@t_x0_1);
ASSERT t_x0_1@x0_1 /= 0bin1000000000000000000000000000000000;

ASSERT z1 = BVPLUS(33,y1,k1);
ASSERT z1 & y1 = y1;


p_z1 : BITVECTOR(2);
ASSERT BVLE( p_z1 , 0bin10);
ASSERT BVGE( p_z1 , 0bin00);
ASSERT p_z1@z1 = BVPLUS( 35, BVMULT( 35, 0bin00000000000000000000000000000000011, 0bin00@t0_1 ),0bin000000000000000000000000000000000@p_z1);
t_t0_1 : BITVECTOR(3);
ASSERT BVLE( t_t0_1, 0bin111);
ASSERT BVGE( t_t0_1, 0bin000);
ASSERT t_t0_1@t0_1 = BVPLUS( 36 , 0bin000@t1_1, 0bin000@t2_1, 0bin000@t3_1, 0bin000@t4_1,0bin000@t5_1,0bin000@t6_1,0bin000@t7_1,0bin000000000000000000000000000000000@t_t0_1);
ASSERT (IF t0_1 = 0bin000000000000000000000000000000000 THEN t_t0_1 = 0bin000 ELSE BVGE( t_t0_1 , 0bin000) ENDIF);
ASSERT x0_2 = BVPLUS(33,t1_1,x1_1);
ASSERT x0_2 & t1_1 = t1_1;


ASSERT x1_2 = BVPLUS(33,t2_1,x2_1);
ASSERT x1_2 & t2_1 = t2_1;


ASSERT x2_2 = BVPLUS(33,t3_1,x3_1);
ASSERT x2_2 & t3_1 = t3_1;


ASSERT x3_2 = BVPLUS(33,t4_1,x4_1);
ASSERT x3_2 & t4_1 = t4_1;


ASSERT x4_2 = BVPLUS(33,t5_1,x5_1);
ASSERT x4_2 & t5_1 = t5_1;


ASSERT x5_2 = BVPLUS(33,t6_1,x6_1);
ASSERT x5_2 & t6_1 = t6_1;


ASSERT x6_2 = BVPLUS(33,t7_1,x7_1);
ASSERT x6_2 & t7_1 = t7_1;


t_x0_2 : BITVECTOR(1);
ASSERT t_x0_2@x0_2 = BVPLUS( 34 , 0bin0@x7_3, 0bin0@y2, 0bin000000000000000000000000000000000@t_x0_2);
ASSERT t_x0_2@x0_2 /= 0bin1000000000000000000000000000000000;

ASSERT z2 = BVPLUS(33,y2,k2);
ASSERT z2 & y2 = y2;


p_z2 : BITVECTOR(2);
ASSERT BVLE( p_z2 , 0bin10);
ASSERT BVGE( p_z2 , 0bin00);
ASSERT p_z2@z2 = BVPLUS( 35, BVMULT( 35, 0bin00000000000000000000000000000000011, 0bin00@t0_2 ),0bin000000000000000000000000000000000@p_z2);
t_t0_2 : BITVECTOR(3);
ASSERT BVLE( t_t0_2, 0bin111);
ASSERT BVGE( t_t0_2, 0bin000);
ASSERT t_t0_2@t0_2 = BVPLUS( 36 , 0bin000@t1_2, 0bin000@t2_2, 0bin000@t3_2, 0bin000@t4_2,0bin000@t5_2,0bin000@t6_2,0bin000@t7_2,0bin000000000000000000000000000000000@t_t0_2);
ASSERT (IF t0_2 = 0bin000000000000000000000000000000000 THEN t_t0_2 = 0bin000 ELSE BVGE( t_t0_2 , 0bin000) ENDIF);
ASSERT x0_3 = BVPLUS(33,t1_2,x1_2);
ASSERT x0_3 & t1_2 = t1_2;


ASSERT x1_3 = BVPLUS(33,t2_2,x2_2);
ASSERT x1_3 & t2_2 = t2_2;


ASSERT x2_3 = BVPLUS(33,t3_2,x3_2);
ASSERT x2_3 & t3_2 = t3_2;


ASSERT x3_3 = BVPLUS(33,t4_2,x4_2);
ASSERT x3_3 & t4_2 = t4_2;


ASSERT x4_3 = BVPLUS(33,t5_2,x5_2);
ASSERT x4_3 & t5_2 = t5_2;


ASSERT x5_3 = BVPLUS(33,t6_2,x6_2);
ASSERT x5_3 & t6_2 = t6_2;


ASSERT x6_3 = BVPLUS(33,t7_2,x7_2);
ASSERT x6_3 & t7_2 = t7_2;


t_x0_3 : BITVECTOR(1);
ASSERT t_x0_3@x0_3 = BVPLUS( 34 , 0bin0@x7_4, 0bin0@y3, 0bin000000000000000000000000000000000@t_x0_3);
ASSERT t_x0_3@x0_3 /= 0bin1000000000000000000000000000000000;

ASSERT z3 = BVPLUS(33,y3,k3);
ASSERT z3 & y3 = y3;


p_z3 : BITVECTOR(2);
ASSERT BVLE( p_z3 , 0bin10);
ASSERT BVGE( p_z3 , 0bin00);
ASSERT p_z3@z3 = BVPLUS( 35, BVMULT( 35, 0bin00000000000000000000000000000000011, 0bin00@t0_3 ),0bin000000000000000000000000000000000@p_z3);
t_t0_3 : BITVECTOR(3);
ASSERT BVLE( t_t0_3, 0bin111);
ASSERT BVGE( t_t0_3, 0bin000);
ASSERT t_t0_3@t0_3 = BVPLUS( 36 , 0bin000@t1_3, 0bin000@t2_3, 0bin000@t3_3, 0bin000@t4_3,0bin000@t5_3,0bin000@t6_3,0bin000@t7_3,0bin000000000000000000000000000000000@t_t0_3);
ASSERT (IF t0_3 = 0bin000000000000000000000000000000000 THEN t_t0_3 = 0bin000 ELSE BVGE( t_t0_3 , 0bin000) ENDIF);
ASSERT x0_4 = BVPLUS(33,t1_3,x1_3);
ASSERT x0_4 & t1_3 = t1_3;


ASSERT x1_4 = BVPLUS(33,t2_3,x2_3);
ASSERT x1_4 & t2_3 = t2_3;


ASSERT x2_4 = BVPLUS(33,t3_3,x3_3);
ASSERT x2_4 & t3_3 = t3_3;


ASSERT x3_4 = BVPLUS(33,t4_3,x4_3);
ASSERT x3_4 & t4_3 = t4_3;


ASSERT x4_4 = BVPLUS(33,t5_3,x5_3);
ASSERT x4_4 & t5_3 = t5_3;


ASSERT x5_4 = BVPLUS(33,t6_3,x6_3);
ASSERT x5_4 & t6_3 = t6_3;


ASSERT x6_4 = BVPLUS(33,t7_3,x7_3);
ASSERT x6_4 & t7_3 = t7_3;


t_x0_4 : BITVECTOR(1);
ASSERT t_x0_4@x0_4 = BVPLUS( 34 , 0bin0@x7_5, 0bin0@y4, 0bin000000000000000000000000000000000@t_x0_4);
ASSERT t_x0_4@x0_4 /= 0bin1000000000000000000000000000000000;

ASSERT z4 = BVPLUS(33,y4,k4);
ASSERT z4 & y4 = y4;


p_z4 : BITVECTOR(2);
ASSERT BVLE( p_z4 , 0bin10);
ASSERT BVGE( p_z4 , 0bin00);
ASSERT p_z4@z4 = BVPLUS( 35, BVMULT( 35, 0bin00000000000000000000000000000000011, 0bin00@t0_4 ),0bin000000000000000000000000000000000@p_z4);
t_t0_4 : BITVECTOR(3);
ASSERT BVLE( t_t0_4, 0bin111);
ASSERT BVGE( t_t0_4, 0bin000);
ASSERT t_t0_4@t0_4 = BVPLUS( 36 , 0bin000@t1_4, 0bin000@t2_4, 0bin000@t3_4, 0bin000@t4_4,0bin000@t5_4,0bin000@t6_4,0bin000@t7_4,0bin000000000000000000000000000000000@t_t0_4);
ASSERT (IF t0_4 = 0bin000000000000000000000000000000000 THEN t_t0_4 = 0bin000 ELSE BVGE( t_t0_4 , 0bin000) ENDIF);
ASSERT x0_5 = BVPLUS(33,t1_4,x1_4);
ASSERT x0_5 & t1_4 = t1_4;


ASSERT x1_5 = BVPLUS(33,t2_4,x2_4);
ASSERT x1_5 & t2_4 = t2_4;


ASSERT x2_5 = BVPLUS(33,t3_4,x3_4);
ASSERT x2_5 & t3_4 = t3_4;


ASSERT x3_5 = BVPLUS(33,t4_4,x4_4);
ASSERT x3_5 & t4_4 = t4_4;


ASSERT x4_5 = BVPLUS(33,t5_4,x5_4);
ASSERT x4_5 & t5_4 = t5_4;


ASSERT x5_5 = BVPLUS(33,t6_4,x6_4);
ASSERT x5_5 & t6_4 = t6_4;


ASSERT x6_5 = BVPLUS(33,t7_4,x7_4);
ASSERT x6_5 & t7_4 = t7_4;


t_x0_5 : BITVECTOR(1);
ASSERT t_x0_5@x0_5 = BVPLUS( 34 , 0bin0@x7_6, 0bin0@y5, 0bin000000000000000000000000000000000@t_x0_5);
ASSERT t_x0_5@x0_5 /= 0bin1000000000000000000000000000000000;

ASSERT z5 = BVPLUS(33,y5,k5);
ASSERT z5 & y5 = y5;


p_z5 : BITVECTOR(2);
ASSERT BVLE( p_z5 , 0bin10);
ASSERT BVGE( p_z5 , 0bin00);
ASSERT p_z5@z5 = BVPLUS( 35, BVMULT( 35, 0bin00000000000000000000000000000000011, 0bin00@t0_5 ),0bin000000000000000000000000000000000@p_z5);
t_t0_5 : BITVECTOR(3);
ASSERT BVLE( t_t0_5, 0bin111);
ASSERT BVGE( t_t0_5, 0bin000);
ASSERT t_t0_5@t0_5 = BVPLUS( 36 , 0bin000@t1_5, 0bin000@t2_5, 0bin000@t3_5, 0bin000@t4_5,0bin000@t5_5,0bin000@t6_5,0bin000@t7_5,0bin000000000000000000000000000000000@t_t0_5);
ASSERT (IF t0_5 = 0bin000000000000000000000000000000000 THEN t_t0_5 = 0bin000 ELSE BVGE( t_t0_5 , 0bin000) ENDIF);
ASSERT x0_6 = BVPLUS(33,t1_5,x1_5);
ASSERT x0_6 & t1_5 = t1_5;


ASSERT x1_6 = BVPLUS(33,t2_5,x2_5);
ASSERT x1_6 & t2_5 = t2_5;


ASSERT x2_6 = BVPLUS(33,t3_5,x3_5);
ASSERT x2_6 & t3_5 = t3_5;


ASSERT x3_6 = BVPLUS(33,t4_5,x4_5);
ASSERT x3_6 & t4_5 = t4_5;


ASSERT x4_6 = BVPLUS(33,t5_5,x5_5);
ASSERT x4_6 & t5_5 = t5_5;


ASSERT x5_6 = BVPLUS(33,t6_5,x6_5);
ASSERT x5_6 & t6_5 = t6_5;


ASSERT x6_6 = BVPLUS(33,t7_5,x7_5);
ASSERT x6_6 & t7_5 = t7_5;


t_x0_6 : BITVECTOR(1);
ASSERT t_x0_6@x0_6 = BVPLUS( 34 , 0bin0@x7_7, 0bin0@y6, 0bin000000000000000000000000000000000@t_x0_6);
ASSERT t_x0_6@x0_6 /= 0bin1000000000000000000000000000000000;

ASSERT z6 = BVPLUS(33,y6,k6);
ASSERT z6 & y6 = y6;


p_z6 : BITVECTOR(2);
ASSERT BVLE( p_z6 , 0bin10);
ASSERT BVGE( p_z6 , 0bin00);
ASSERT p_z6@z6 = BVPLUS( 35, BVMULT( 35, 0bin00000000000000000000000000000000011, 0bin00@t0_6 ),0bin000000000000000000000000000000000@p_z6);
t_t0_6 : BITVECTOR(3);
ASSERT BVLE( t_t0_6, 0bin111);
ASSERT BVGE( t_t0_6, 0bin000);
ASSERT t_t0_6@t0_6 = BVPLUS( 36 , 0bin000@t1_6, 0bin000@t2_6, 0bin000@t3_6, 0bin000@t4_6,0bin000@t5_6,0bin000@t6_6,0bin000@t7_6,0bin000000000000000000000000000000000@t_t0_6);
ASSERT (IF t0_6 = 0bin000000000000000000000000000000000 THEN t_t0_6 = 0bin000 ELSE BVGE( t_t0_6 , 0bin000) ENDIF);
ASSERT x0_7 = BVPLUS(33,t1_6,x1_6);
ASSERT x0_7 & t1_6 = t1_6;


ASSERT x1_7 = BVPLUS(33,t2_6,x2_6);
ASSERT x1_7 & t2_6 = t2_6;


ASSERT x2_7 = BVPLUS(33,t3_6,x3_6);
ASSERT x2_7 & t3_6 = t3_6;


ASSERT x3_7 = BVPLUS(33,t4_6,x4_6);
ASSERT x3_7 & t4_6 = t4_6;


ASSERT x4_7 = BVPLUS(33,t5_6,x5_6);
ASSERT x4_7 & t5_6 = t5_6;


ASSERT x5_7 = BVPLUS(33,t6_6,x6_6);
ASSERT x5_7 & t6_6 = t6_6;


ASSERT x6_7 = BVPLUS(33,t7_6,x7_6);
ASSERT x6_7 & t7_6 = t7_6;


t_x0_7 : BITVECTOR(1);
ASSERT t_x0_7@x0_7 = BVPLUS( 34 , 0bin0@x7_8, 0bin0@y7, 0bin000000000000000000000000000000000@t_x0_7);
ASSERT t_x0_7@x0_7 /= 0bin1000000000000000000000000000000000;

ASSERT z7 = BVPLUS(33,y7,k7);
ASSERT z7 & y7 = y7;


p_z7 : BITVECTOR(2);
ASSERT BVLE( p_z7 , 0bin10);
ASSERT BVGE( p_z7 , 0bin00);
ASSERT p_z7@z7 = BVPLUS( 35, BVMULT( 35, 0bin00000000000000000000000000000000011, 0bin00@t0_7 ),0bin000000000000000000000000000000000@p_z7);
t_t0_7 : BITVECTOR(3);
ASSERT BVLE( t_t0_7, 0bin111);
ASSERT BVGE( t_t0_7, 0bin000);
ASSERT t_t0_7@t0_7 = BVPLUS( 36 , 0bin000@t1_7, 0bin000@t2_7, 0bin000@t3_7, 0bin000@t4_7,0bin000@t5_7,0bin000@t6_7,0bin000@t7_7,0bin000000000000000000000000000000000@t_t0_7);
ASSERT (IF t0_7 = 0bin000000000000000000000000000000000 THEN t_t0_7 = 0bin000 ELSE BVGE( t_t0_7 , 0bin000) ENDIF);
ASSERT x0_8 = BVPLUS(33,t1_7,x1_7);
ASSERT x0_8 & t1_7 = t1_7;


ASSERT x1_8 = BVPLUS(33,t2_7,x2_7);
ASSERT x1_8 & t2_7 = t2_7;


ASSERT x2_8 = BVPLUS(33,t3_7,x3_7);
ASSERT x2_8 & t3_7 = t3_7;


ASSERT x3_8 = BVPLUS(33,t4_7,x4_7);
ASSERT x3_8 & t4_7 = t4_7;


ASSERT x4_8 = BVPLUS(33,t5_7,x5_7);
ASSERT x4_8 & t5_7 = t5_7;


ASSERT x5_8 = BVPLUS(33,t6_7,x6_7);
ASSERT x5_8 & t6_7 = t6_7;


ASSERT x6_8 = BVPLUS(33,t7_7,x7_7);
ASSERT x6_8 & t7_7 = t7_7;


ASSERT wk = 0bin0000000001;
QUERY FALSE;
COUNTEREXAMPLE;
